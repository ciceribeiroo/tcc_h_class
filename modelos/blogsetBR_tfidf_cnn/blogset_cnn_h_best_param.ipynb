{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import tensorflow \n",
    "tensorflow.random.set_seed(1) \n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alici\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D, Convolution1D\n",
    "from keras.optimizers import Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    all_words = text.split(\" \")\n",
    "    clean_text = [i for i in all_words if i not in stopwords and i!=\"\"]\n",
    "    return \" \".join(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    import re\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_texts(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    clean_text = remove_stopwords(text)\n",
    "    clean_text = remove_html_tags(clean_text)\n",
    "    clean_text = lower_texts(clean_text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_gender(filters = 100, kernel_size = 3, strides = 1, \n",
    "                 dropout_rate = 0.4, pool_size = 4, dense_units = 512, max_len = 1000):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv1D(filters = filters, \n",
    "                     kernel_size = kernel_size,\n",
    "                     strides = strides, \n",
    "                     activation = 'relu', \n",
    "                     input_shape = (max_len, 1) ))\n",
    "\n",
    "    model.add(MaxPooling1D(pool_size = pool_size, strides = 1))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(dropout_rate))\n",
    "        \n",
    "    model.add(Dense(units = dense_units, activation = 'relu'))\n",
    "    model.add(Dense(units = 2, activation = 'softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer = Adadelta(\n",
    "       learning_rate=1, name=\"Adadelta\"\n",
    "    ), metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 85s 1s/step - loss: 0.6461 - accuracy: 0.6571 - val_loss: 0.5791 - val_accuracy: 0.7278\n",
      "16/16 [==============================] - 4s 227ms/step\n",
      "64/64 [==============================] - 72s 1s/step - loss: 1.0722 - accuracy: 0.3966 - val_loss: 1.0345 - val_accuracy: 0.4497\n",
      "16/16 [==============================] - 3s 186ms/step\n",
      "juntos: 0.4337421742227465\n",
      "26/26 [==============================] - 22s 831ms/step - loss: 1.0914 - accuracy: 0.3929 - val_loss: 1.0693 - val_accuracy: 0.4400\n",
      "7/7 [==============================] - 1s 171ms/step\n",
      "fem: 0.3980842911877394\n",
      "39/39 [==============================] - 48s 1s/step - loss: 1.0905 - accuracy: 0.3834 - val_loss: 1.0560 - val_accuracy: 0.4137\n",
      "10/10 [==============================] - 2s 185ms/step\n",
      "masc: 0.3063554802685237\n",
      "separado: 0.40223775987569876\n",
      "64/64 [==============================] - 63s 963ms/step - loss: 0.6469 - accuracy: 0.6350 - val_loss: 0.5825 - val_accuracy: 0.7278\n",
      "16/16 [==============================] - 3s 163ms/step\n",
      "64/64 [==============================] - 64s 985ms/step - loss: 1.0727 - accuracy: 0.3995 - val_loss: 1.0405 - val_accuracy: 0.4320\n",
      "16/16 [==============================] - 3s 172ms/step\n",
      "juntos: 0.40730170532075355\n",
      "26/26 [==============================] - 37s 1s/step - loss: 1.0982 - accuracy: 0.3941 - val_loss: 1.0725 - val_accuracy: 0.4271\n",
      "6/6 [==============================] - 2s 387ms/step\n",
      "fem: 0.37423946483625664\n",
      "39/39 [==============================] - 80s 2s/step - loss: 1.0858 - accuracy: 0.3875 - val_loss: 1.0522 - val_accuracy: 0.4571\n",
      "10/10 [==============================] - 6s 585ms/step\n",
      "masc: 0.34371643394199786\n",
      "separado: 0.4257702079938321\n",
      "64/64 [==============================] - 85s 1s/step - loss: 0.6474 - accuracy: 0.6360 - val_loss: 0.5815 - val_accuracy: 0.7318\n",
      "16/16 [==============================] - 6s 379ms/step\n",
      "64/64 [==============================] - 84s 1s/step - loss: 1.0717 - accuracy: 0.3980 - val_loss: 1.0337 - val_accuracy: 0.4497\n",
      "16/16 [==============================] - 6s 382ms/step\n",
      "juntos: 0.42873082520284944\n",
      "26/26 [==============================] - 19s 707ms/step - loss: 1.1006 - accuracy: 0.3855 - val_loss: 1.0758 - val_accuracy: 0.4118\n",
      "7/7 [==============================] - 1s 128ms/step\n",
      "fem: 0.3412698412698412\n",
      "39/39 [==============================] - 92s 2s/step - loss: 1.0925 - accuracy: 0.3834 - val_loss: 1.0591 - val_accuracy: 0.4389\n",
      "10/10 [==============================] - 7s 739ms/step\n",
      "masc: 0.3289549772821148\n",
      "separado: 0.41055782445295214\n",
      "64/64 [==============================] - 121s 2s/step - loss: 0.6546 - accuracy: 0.6281 - val_loss: 0.5921 - val_accuracy: 0.7061\n",
      "16/16 [==============================] - 12s 743ms/step\n",
      "64/64 [==============================] - 139s 2s/step - loss: 1.0726 - accuracy: 0.4000 - val_loss: 1.0400 - val_accuracy: 0.4339\n",
      "16/16 [==============================] - 8s 476ms/step\n",
      "juntos: 0.40638576195135245\n",
      "26/26 [==============================] - 24s 890ms/step - loss: 1.1012 - accuracy: 0.3978 - val_loss: 1.0818 - val_accuracy: 0.4093\n",
      "7/7 [==============================] - 2s 226ms/step\n",
      "fem: 0.35371318822023046\n",
      "39/39 [==============================] - 57s 1s/step - loss: 1.0801 - accuracy: 0.4089 - val_loss: 1.0451 - val_accuracy: 0.4486\n",
      "10/10 [==============================] - 2s 232ms/step\n",
      "masc: 0.33571393145861234\n",
      "separado: 0.4143108220682059\n",
      "64/64 [==============================] - 135s 2s/step - loss: 0.6589 - accuracy: 0.6399 - val_loss: 0.6006 - val_accuracy: 0.6943\n",
      "16/16 [==============================] - 15s 904ms/step\n",
      "64/64 [==============================] - 129s 2s/step - loss: 1.0714 - accuracy: 0.3926 - val_loss: 1.0323 - val_accuracy: 0.4675\n",
      "16/16 [==============================] - 9s 588ms/step\n",
      "juntos: 0.45169742730209905\n",
      "26/26 [==============================] - 29s 1s/step - loss: 1.0892 - accuracy: 0.3953 - val_loss: 1.0667 - val_accuracy: 0.4615\n",
      "7/7 [==============================] - 3s 359ms/step\n",
      "fem: 0.4342227202519761\n",
      "39/39 [==============================] - 70s 2s/step - loss: 1.0873 - accuracy: 0.3826 - val_loss: 1.0499 - val_accuracy: 0.4580\n",
      "9/9 [==============================] - 4s 430ms/step\n",
      "masc: 0.3506219692177946\n",
      "separado: 0.45028180354267316\n",
      "64/64 [==============================] - 76s 1s/step - loss: 0.6584 - accuracy: 0.6261 - val_loss: 0.5937 - val_accuracy: 0.7120\n",
      "16/16 [==============================] - 5s 328ms/step\n",
      "64/64 [==============================] - 97s 1s/step - loss: 1.0716 - accuracy: 0.4000 - val_loss: 1.0351 - val_accuracy: 0.4517\n",
      "16/16 [==============================] - 5s 329ms/step\n",
      "juntos: 0.43384843369964105\n",
      "26/26 [==============================] - 30s 1s/step - loss: 1.0981 - accuracy: 0.3978 - val_loss: 1.0740 - val_accuracy: 0.4444\n",
      "7/7 [==============================] - 2s 332ms/step\n",
      "fem: 0.3950756558331096\n",
      "39/39 [==============================] - 75s 2s/step - loss: 1.0895 - accuracy: 0.3883 - val_loss: 1.0541 - val_accuracy: 0.4304\n",
      "10/10 [==============================] - 6s 511ms/step\n",
      "masc: 0.313433538641201\n",
      "separado: 0.42923219607127655\n",
      "64/64 [==============================] - 92s 1s/step - loss: 0.6516 - accuracy: 0.6296 - val_loss: 0.5818 - val_accuracy: 0.7318\n",
      "16/16 [==============================] - 8s 506ms/step\n",
      "64/64 [==============================] - 92s 1s/step - loss: 1.0710 - accuracy: 0.3985 - val_loss: 1.0345 - val_accuracy: 0.4458\n",
      "16/16 [==============================] - 7s 413ms/step\n",
      "juntos: 0.42882528385513563\n",
      "26/26 [==============================] - 29s 981ms/step - loss: 1.0922 - accuracy: 0.4076 - val_loss: 1.0700 - val_accuracy: 0.4421\n",
      "6/6 [==============================] - 2s 288ms/step\n",
      "fem: 0.39179621484291943\n",
      "39/39 [==============================] - 93s 2s/step - loss: 1.0932 - accuracy: 0.3810 - val_loss: 1.0565 - val_accuracy: 0.4511\n",
      "10/10 [==============================] - 9s 813ms/step\n",
      "masc: 0.3387790775850477\n",
      "separado: 0.4292905270342742\n",
      "64/64 [==============================] - 115s 2s/step - loss: 0.6408 - accuracy: 0.6571 - val_loss: 0.5726 - val_accuracy: 0.7318\n",
      "16/16 [==============================] - 9s 587ms/step\n",
      "64/64 [==============================] - 105s 2s/step - loss: 1.0702 - accuracy: 0.4015 - val_loss: 1.0335 - val_accuracy: 0.4497\n",
      "16/16 [==============================] - 10s 615ms/step\n",
      "juntos: 0.4300741235396484\n",
      "26/26 [==============================] - 29s 1s/step - loss: 1.0952 - accuracy: 0.3978 - val_loss: 1.0693 - val_accuracy: 0.4369\n",
      "7/7 [==============================] - 2s 276ms/step\n",
      "fem: 0.39075630252100835\n",
      "39/39 [==============================] - 63s 2s/step - loss: 1.0933 - accuracy: 0.3842 - val_loss: 1.0593 - val_accuracy: 0.4485\n",
      "10/10 [==============================] - 5s 452ms/step\n",
      "masc: 0.3369458128078818\n",
      "separado: 0.4287071722932814\n",
      "64/64 [==============================] - 92s 1s/step - loss: 0.6462 - accuracy: 0.6483 - val_loss: 0.5762 - val_accuracy: 0.7041\n",
      "16/16 [==============================] - 7s 459ms/step\n",
      "64/64 [==============================] - 89s 1s/step - loss: 1.0710 - accuracy: 0.3931 - val_loss: 1.0354 - val_accuracy: 0.4438\n",
      "16/16 [==============================] - 7s 436ms/step\n",
      "juntos: 0.4201165516321892\n",
      "26/26 [==============================] - 37s 1s/step - loss: 1.0904 - accuracy: 0.3867 - val_loss: 1.0689 - val_accuracy: 0.4602\n",
      "8/8 [==============================] - 3s 340ms/step\n",
      "fem: 0.4405844878043779\n",
      "39/39 [==============================] - 62s 2s/step - loss: 1.0941 - accuracy: 0.3810 - val_loss: 1.0576 - val_accuracy: 0.4484\n",
      "9/9 [==============================] - 4s 430ms/step\n",
      "masc: 0.33377279718743136\n",
      "separado: 0.44620366542648476\n",
      "64/64 [==============================] - 107s 2s/step - loss: 0.6465 - accuracy: 0.6463 - val_loss: 0.5741 - val_accuracy: 0.7377\n",
      "16/16 [==============================] - 9s 554ms/step\n",
      "64/64 [==============================] - 106s 2s/step - loss: 1.0737 - accuracy: 0.3966 - val_loss: 1.0371 - val_accuracy: 0.4517\n",
      "16/16 [==============================] - 9s 597ms/step\n",
      "juntos: 0.43549298569509537\n",
      "26/26 [==============================] - 28s 1s/step - loss: 1.0906 - accuracy: 0.3966 - val_loss: 1.0683 - val_accuracy: 0.4328\n",
      "7/7 [==============================] - 2s 317ms/step\n",
      "fem: 0.39277930333032307\n",
      "39/39 [==============================] - 88s 2s/step - loss: 1.0912 - accuracy: 0.3785 - val_loss: 1.0553 - val_accuracy: 0.4542\n",
      "10/10 [==============================] - 6s 619ms/step\n",
      "masc: 0.34111692514321\n",
      "separado: 0.4260679971183136\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RESULTADOS FINAIS\n",
      "flat: 0.4276215272421511\n",
      "local fem: 0.39125214700977823\n",
      "local masc: 0.33294109435338154\n",
      "hierq: 0.4262659975876993\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "VETORES\n",
      "flat: [0.4337421742227465, 0.40730170532075355, 0.42873082520284944, 0.40638576195135245, 0.45169742730209905, 0.43384843369964105, 0.42882528385513563, 0.4300741235396484, 0.4201165516321892, 0.43549298569509537]\n",
      "local fem: [0.3980842911877394, 0.37423946483625664, 0.3412698412698412, 0.35371318822023046, 0.4342227202519761, 0.3950756558331096, 0.39179621484291943, 0.39075630252100835, 0.4405844878043779, 0.39277930333032307]\n",
      "local masc: [0.3063554802685237, 0.34371643394199786, 0.3289549772821148, 0.33571393145861234, 0.3506219692177946, 0.313433538641201, 0.3387790775850477, 0.3369458128078818, 0.33377279718743136, 0.34111692514321]\n",
      "hierq: [0.40223775987569876, 0.4257702079938321, 0.41055782445295214, 0.4143108220682059, 0.45028180354267316, 0.42923219607127655, 0.4292905270342742, 0.4287071722932814, 0.44620366542648476, 0.4260679971183136]\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(r\"C:\\Users\\alici\\Documents\\tcc\\github2\\tcc-v2\\blogset-br\\particoes\\houdout\\train.csv\")\n",
    "df_test = pd.read_csv(r\"C:\\Users\\alici\\Documents\\tcc\\github2\\tcc-v2\\blogset-br\\particoes\\houdout\\test.csv\")\n",
    "\n",
    "f = []\n",
    "l_fem = []\n",
    "l_masc = []\n",
    "h_total = []\n",
    "for _ in range(10):\n",
    "    X_train = df_train[\"Texts\"].apply(clean_text).to_numpy()\n",
    "    X_test = df_test[\"Texts\"].apply(clean_text).to_numpy()\n",
    "    y_train_gender = df_train[\"GenderClass\"].to_numpy()\n",
    "    y_test_gender = df_test[\"GenderClass\"].to_numpy()\n",
    "\n",
    "    num_words = []\n",
    "    for text in (X_train.tolist()+X_test.tolist()):\n",
    "        num_words.append(len(text.split()))\n",
    "\n",
    "    mean = sum(num_words)//len(num_words)\n",
    "\n",
    "    train_texts = X_train.tolist()\n",
    "    test_texts = X_test.tolist()\n",
    "\n",
    "    tfidfvec = TfidfVectorizer(max_features = mean, max_df=0.9)\n",
    "    tfidfvec.fit(train_texts)\n",
    "    tfidf_train = tfidfvec.transform(train_texts).toarray()\n",
    "    tfidf_test = tfidfvec.transform(test_texts).toarray()\n",
    "\n",
    "    X_train = tfidf_train.reshape(tfidf_train.shape[0],tfidf_train.shape[1],1)\n",
    "    X_test = tfidf_test.reshape(tfidf_test.shape[0],tfidf_test.shape[1],1)\n",
    "\n",
    "    y_train_gander_cat = keras.utils.to_categorical(y_train_gender,num_classes=2)\n",
    "    y_test_gender_cat = keras.utils.to_categorical(y_test_gender,num_classes=2)\n",
    "\n",
    "    size = X_test.shape[1]\n",
    "\n",
    "    model_gender = Sequential()\n",
    "    model_gender.add(Conv1D(filters = 100, \n",
    "                        kernel_size = 3,\n",
    "                        strides = 1, \n",
    "                        activation = 'relu', \n",
    "                        input_shape = (size, 1) ))\n",
    "    model_gender.add(MaxPooling1D(pool_size = 4, strides = 1))\n",
    "    model_gender.add(Activation('relu')) # add layer\n",
    "    model_gender.add(Flatten())\n",
    "    model_gender.add(Dropout(0.4))\n",
    "    model_gender.add(Dense(units = 512, activation = 'relu')) #add relu\n",
    "    model_gender.add(Dense(units = 2, activation = 'softmax'))\n",
    "    model_gender.compile(loss='categorical_crossentropy', optimizer = Adadelta(\n",
    "        learning_rate=1, name=\"Adadelta\"\n",
    "    ), metrics = ['accuracy'])\n",
    "\n",
    "    model_gender.fit(X_train,y_train_gander_cat,validation_data=(X_test,y_test_gender_cat), batch_size=32)\n",
    "\n",
    "    y_pred_gender = model_gender.predict(\n",
    "        X_test\n",
    "    )\n",
    "\n",
    "    y_pred_list_gender = [np.argmax(x, axis=-1) for x in y_pred_gender]\n",
    "\n",
    "    df_test[\"PredictGender\"] = y_pred_list_gender\n",
    "\n",
    "    y_train_age = df_train[\"AgeClass\"].to_numpy()\n",
    "    y_test_age = df_test[\"AgeClass\"].to_numpy()\n",
    "\n",
    "    y_train_age = keras.utils.to_categorical(y_train_age,num_classes=3)\n",
    "    y_test_age_cat = keras.utils.to_categorical(y_test_age,num_classes=3)\n",
    "\n",
    "    model_age = Sequential()\n",
    "    model_age.add(Conv1D(filters = 100, \n",
    "                        kernel_size = 3,\n",
    "                        strides = 1, \n",
    "                        activation = 'relu', \n",
    "                        input_shape = (size, 1) ))\n",
    "    model_age.add(MaxPooling1D(pool_size = 4, strides = 1))\n",
    "    model_age.add(Activation('relu')) # add layer\n",
    "    model_age.add(Flatten())\n",
    "    model_age.add(Dropout(0.4))\n",
    "    model_age.add(Dense(units = 512, activation = 'relu')) #add relu\n",
    "    model_age.add(Dense(units = 3, activation = 'softmax'))\n",
    "    model_age.compile(loss='categorical_crossentropy', optimizer = Adadelta(\n",
    "        learning_rate=1, name=\"Adadelta\"\n",
    "    ), metrics = ['accuracy'])\n",
    "\n",
    "    model_age.fit(X_train,y_train_age,validation_data=(X_test,y_test_age_cat), batch_size=32)\n",
    "\n",
    "    y_pred_age = model_age.predict(\n",
    "        X_test\n",
    "    )\n",
    "\n",
    "    y_pred_list_age = [np.argmax(x, axis=-1) for x in y_pred_age]\n",
    "\n",
    "    print(\"juntos: \", end=\"\")\n",
    "    print(metrics.f1_score(y_test_age, y_pred_list_age, average='macro'))\n",
    "    f.append(metrics.f1_score(y_test_age, y_pred_list_age, average='macro'))\n",
    "\n",
    "    df_train_fem = df_train[df_train[\"GenderClass\"]==1]\n",
    "    df_test_fem = df_test[df_test[\"PredictGender\"]==1]\n",
    "\n",
    "    X_train_fem = df_train_fem[\"Texts\"].apply(clean_text).to_numpy()\n",
    "    X_test_fem = df_test_fem[\"Texts\"].apply(clean_text).to_numpy()\n",
    "    y_train_fem = df_train_fem[\"AgeClass\"].to_numpy()\n",
    "    y_test_fem = df_test_fem[\"AgeClass\"].to_numpy()\n",
    "\n",
    "    num_words_fem = []\n",
    "    for text in (X_train_fem.tolist()+X_test_fem.tolist()):\n",
    "        num_words_fem.append(len(text.split()))\n",
    "\n",
    "    mean_fem = sum(num_words_fem)//len(num_words_fem)\n",
    "\n",
    "    train_texts_fem = X_train_fem.tolist()\n",
    "    test_texts_fem = X_test_fem.tolist()\n",
    "\n",
    "    tfidfvec_fem = TfidfVectorizer(max_features = mean_fem, max_df=0.9)\n",
    "    tfidfvec_fem.fit(train_texts_fem)\n",
    "    tfidf_train_fem = tfidfvec_fem.transform(train_texts_fem).toarray()\n",
    "    tfidf_test_fem = tfidfvec_fem.transform(test_texts_fem).toarray()\n",
    "\n",
    "    X_train_fem = tfidf_train_fem.reshape(tfidf_train_fem.shape[0],tfidf_train_fem.shape[1],1)\n",
    "    X_test_fem = tfidf_test_fem.reshape(tfidf_test_fem.shape[0],tfidf_test_fem.shape[1],1)\n",
    "\n",
    "    y_train_fem = keras.utils.to_categorical(y_train_fem,num_classes=3)\n",
    "    y_test_fem_cat = keras.utils.to_categorical(y_test_fem,num_classes=3)\n",
    "\n",
    "    size_fem = X_test_fem.shape[1]\n",
    "\n",
    "    model_fem = Sequential()\n",
    "    model_fem.add(Conv1D(filters = 100, \n",
    "                        kernel_size = 3,\n",
    "                        strides = 1, \n",
    "                        activation = 'relu', \n",
    "                        input_shape = (size_fem, 1) ))\n",
    "    model_fem.add(MaxPooling1D(pool_size = 4, strides = 1))\n",
    "    model_fem.add(Activation('relu')) # add layer\n",
    "    model_fem.add(Flatten())\n",
    "    model_fem.add(Dropout(0.4))\n",
    "    model_fem.add(Dense(units = 512, activation = 'relu')) #add relu\n",
    "    model_fem.add(Dense(units = 3, activation = 'softmax'))\n",
    "\n",
    "    model_fem.compile(loss='categorical_crossentropy', optimizer = Adadelta(\n",
    "        learning_rate=1, name=\"Adadelta\"\n",
    "    ), metrics = ['accuracy'])\n",
    "\n",
    "    model_fem.fit(X_train_fem,y_train_fem,validation_data=(X_test_fem, y_test_fem_cat), batch_size=32)\n",
    "\n",
    "    y_pred_fem = model_fem.predict(\n",
    "        X_test_fem\n",
    "    )\n",
    "\n",
    "    y_pred_list_fem = [np.argmax(x, axis=-1) for x in y_pred_fem]\n",
    "    print(\"fem: \", end=\"\")\n",
    "    print(metrics.f1_score(y_test_fem, y_pred_list_fem, average='macro'))\n",
    "    l_fem.append(metrics.f1_score(y_test_fem, y_pred_list_fem, average='macro'))\n",
    "\n",
    "\n",
    "    df_train_masc = df_train[df_train[\"GenderClass\"]==0]\n",
    "    df_test_masc = df_test[df_test[\"PredictGender\"]==0]\n",
    "\n",
    "    X_train_masc = df_train_masc[\"Texts\"].apply(clean_text).to_numpy()\n",
    "    X_test_masc = df_test_masc[\"Texts\"].apply(clean_text).to_numpy()\n",
    "    y_train_masc = df_train_masc[\"AgeClass\"].to_numpy()\n",
    "    y_test_masc = df_test_masc[\"AgeClass\"].to_numpy()\n",
    "\n",
    "    num_words_masc = []\n",
    "    for text in (X_train_masc.tolist()+X_test_masc.tolist()):\n",
    "        num_words_masc.append(len(text.split()))\n",
    "\n",
    "    mean_masc = sum(num_words_masc)//len(num_words_masc)\n",
    "\n",
    "    train_texts_masc = X_train_masc.tolist()\n",
    "    test_texts_masc = X_test_masc.tolist()\n",
    "\n",
    "    tfidfvec_masc = TfidfVectorizer(max_features = mean_masc, max_df=0.9)\n",
    "    tfidfvec_masc.fit(train_texts_masc)\n",
    "    tfidf_train_masc = tfidfvec_masc.transform(train_texts_masc).toarray()\n",
    "    tfidf_test_masc = tfidfvec_masc.transform(test_texts_masc).toarray()\n",
    "\n",
    "    X_train_masc = tfidf_train_masc.reshape(tfidf_train_masc.shape[0],tfidf_train_masc.shape[1],1)\n",
    "    X_test_masc = tfidf_test_masc.reshape(tfidf_test_masc.shape[0],tfidf_test_masc.shape[1],1)\n",
    "\n",
    "    y_train_masc = keras.utils.to_categorical(y_train_masc,num_classes=3)\n",
    "    y_test_masc_cat = keras.utils.to_categorical(y_test_masc,num_classes=3)\n",
    "\n",
    "    size_masc = X_test_masc.shape[1]\n",
    "\n",
    "    model_masc = Sequential()\n",
    "    model_masc.add(Conv1D(filters = 100, \n",
    "                        kernel_size = 3,\n",
    "                        strides = 1, \n",
    "                        activation = 'relu', \n",
    "                        input_shape = (size_masc, 1) ))\n",
    "    model_masc.add(MaxPooling1D(pool_size = 4, strides = 1))\n",
    "    model_masc.add(Activation('relu')) # add layer\n",
    "    model_masc.add(Flatten())\n",
    "    model_masc.add(Dropout(0.4))\n",
    "    model_masc.add(Dense(units = 512, activation = 'relu')) #add relu\n",
    "    model_masc.add(Dense(units = 3, activation = 'softmax'))\n",
    "\n",
    "    model_masc.compile(loss='categorical_crossentropy', optimizer = Adadelta(\n",
    "        learning_rate=1, name=\"Adadelta\"\n",
    "    ), metrics = ['accuracy'])\n",
    "\n",
    "    model_masc.fit(X_train_masc,y_train_masc,validation_data=(X_test_masc,y_test_masc_cat), batch_size=32)\n",
    "\n",
    "    y_pred_masc = model_masc.predict(\n",
    "        X_test_masc\n",
    "    )\n",
    "\n",
    "    y_pred_list_masc = [np.argmax(x, axis=-1) for x in y_pred_masc]\n",
    "\n",
    "    print(\"masc: \", end=\"\")\n",
    "    print(metrics.f1_score(y_test_masc, y_pred_list_masc, average='macro'))\n",
    "    l_masc.append(metrics.f1_score(y_test_masc, y_pred_list_masc, average='macro'))\n",
    "\n",
    "    y_test_sep = y_test_fem.tolist() + y_test_masc.tolist()\n",
    "    y_pred_list_sep = y_pred_list_fem + y_pred_list_masc\n",
    "    print(\"separado: \", end=\"\")\n",
    "    print(metrics.f1_score(y_test_sep, y_pred_list_sep, average='macro'))\n",
    "    h_total.append(metrics.f1_score(y_test_sep, y_pred_list_sep, average='macro'))\n",
    "\n",
    "print(\"\\n\\n\\n\\n\\n\\nRESULTADOS FINAIS\")\n",
    "print(\"flat: \", end=\"\")\n",
    "print(sum(f)/len(f))\n",
    "print(\"local fem: \", end=\"\")\n",
    "print(sum(l_fem)/len(l_fem))\n",
    "print(\"local masc: \", end=\"\")\n",
    "print(sum(l_masc)/len(l_masc))\n",
    "print(\"hierq: \", end=\"\")\n",
    "print(sum(h_total)/len(h_total))\n",
    "\n",
    "print(\"\\n\\n\\n\\n\\n\\nVETORES\")\n",
    "print(\"flat: \", end=\"\")\n",
    "print(f)\n",
    "print(\"local fem: \", end=\"\")\n",
    "print(l_fem)\n",
    "print(\"local masc: \", end=\"\")\n",
    "print(l_masc)\n",
    "print(\"hierq: \", end=\"\")\n",
    "print(h_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(r'C:\\Users\\alici\\Documents\\tcc\\v3\\melhores_param\\blogsetbr\\param.json', encoding='utf-8') as f:\n",
    "    param = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 0.1, 10, [60], [1], [4], [1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param[\"gender\"][\"params\"][\"batch_size\"], param[\"gender\"][\"params\"][\"dropout_rate\"], param[\"gender\"][\"params\"][\"epochs\"], param[\"gender\"][\"params\"][\"filters\"], param[\"gender\"][\"params\"][\"kernel_size\"], param[\"gender\"][\"params\"][\"pool_size\"], param[\"gender\"][\"params\"][\"strides\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r\"C:\\Users\\alici\\Documents\\tcc\\v3\\particoes\\blogsetbr\\houdout\\train.csv\")\n",
    "df_test = pd.read_csv(r\"C:\\Users\\alici\\Documents\\tcc\\v3\\particoes\\blogsetbr\\houdout\\test.csv\")\n",
    "\n",
    "gender = []\n",
    "for _ in range(10):\n",
    "    X_train = df_train[\"Texts\"].apply(clean_text).to_numpy()\n",
    "    X_test = df_test[\"Texts\"].apply(clean_text).to_numpy()\n",
    "    y_train_gender = df_train[\"GenderClass\"].to_numpy()\n",
    "    y_test_gender = df_test[\"GenderClass\"].to_numpy()\n",
    "\n",
    "    num_words = []\n",
    "    for text in (X_train.tolist()+X_test.tolist()):\n",
    "        num_words.append(len(text.split()))\n",
    "\n",
    "    mean = sum(num_words)//len(num_words)\n",
    "\n",
    "    train_texts = X_train.tolist()\n",
    "    test_texts = X_test.tolist()\n",
    "\n",
    "    tfidfvec = TfidfVectorizer(max_features = mean, max_df=0.9)\n",
    "    tfidfvec.fit(train_texts)\n",
    "    tfidf_train = tfidfvec.transform(train_texts).toarray()\n",
    "    tfidf_test = tfidfvec.transform(test_texts).toarray()\n",
    "\n",
    "    X_train = tfidf_train.reshape(tfidf_train.shape[0],tfidf_train.shape[1],1)\n",
    "    X_test = tfidf_test.reshape(tfidf_test.shape[0],tfidf_test.shape[1],1)\n",
    "\n",
    "    y_train_gander_cat = keras.utils.to_categorical(y_train_gender,num_classes=2)\n",
    "    y_test_gender_cat = keras.utils.to_categorical(y_test_gender,num_classes=2)\n",
    "\n",
    "    size = X_test.shape[1]\n",
    "\n",
    "    model_gender = create_model_gender(filters=[100], kernel_size=[3], strides=[1], dropout_rate=0.4, pool_size=[4], dense_units=512, max_len=size)\n",
    "\n",
    "    model_gender.fit(X_train,y_train_gander_cat,validation_data=(X_test,y_test_gender_cat), batch_size=32)\n",
    "\n",
    "    y_pred_gender = model_gender.predict(\n",
    "        X_test\n",
    "    )\n",
    "\n",
    "    y_pred_list_gender = [np.argmax(x, axis=-1) for x in y_pred_gender]\n",
    "\n",
    "    df_test[\"PredictGender\"] = y_pred_list_gender\n",
    "\n",
    "    gender.append(metrics.f1_score(y_test_gender, y_pred_list_gender, average='macro'))\n",
    "\n",
    "print(sum(gender)/len(gender))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 31s 949ms/step - loss: 0.6355 - accuracy: 0.6567 - val_loss: 0.6701 - val_accuracy: 0.5700\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 30s 954ms/step - loss: 0.5347 - accuracy: 0.7419 - val_loss: 0.5279 - val_accuracy: 0.7535\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 29s 922ms/step - loss: 0.4846 - accuracy: 0.7719 - val_loss: 0.5496 - val_accuracy: 0.7199\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 31s 959ms/step - loss: 0.4442 - accuracy: 0.7961 - val_loss: 0.5872 - val_accuracy: 0.7298\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.4055 - accuracy: 0.8143 - val_loss: 0.5792 - val_accuracy: 0.7239\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 31s 975ms/step - loss: 0.3769 - accuracy: 0.8271 - val_loss: 0.6417 - val_accuracy: 0.7179\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 30s 926ms/step - loss: 0.3722 - accuracy: 0.8291 - val_loss: 0.5523 - val_accuracy: 0.7258\n",
      "16/16 [==============================] - 3s 194ms/step\n",
      "0.714147177555761\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 44s 1s/step - loss: 0.6386 - accuracy: 0.6502 - val_loss: 0.6150 - val_accuracy: 0.6489\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 45s 1s/step - loss: 0.5304 - accuracy: 0.7404 - val_loss: 0.5277 - val_accuracy: 0.7475\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 39s 1s/step - loss: 0.4837 - accuracy: 0.7724 - val_loss: 0.5396 - val_accuracy: 0.7140\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 40s 1s/step - loss: 0.4420 - accuracy: 0.8025 - val_loss: 0.5788 - val_accuracy: 0.7318\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 39s 1s/step - loss: 0.4059 - accuracy: 0.8192 - val_loss: 0.5530 - val_accuracy: 0.7258\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 39s 1s/step - loss: 0.3679 - accuracy: 0.8330 - val_loss: 0.5771 - val_accuracy: 0.7337\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 40s 1s/step - loss: 0.3742 - accuracy: 0.8296 - val_loss: 0.5499 - val_accuracy: 0.7239\n",
      "16/16 [==============================] - 5s 295ms/step\n",
      "0.7077809798270893\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 32s 990ms/step - loss: 0.6412 - accuracy: 0.6586 - val_loss: 0.6094 - val_accuracy: 0.6607\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 29s 914ms/step - loss: 0.5352 - accuracy: 0.7345 - val_loss: 0.5286 - val_accuracy: 0.7436\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 30s 932ms/step - loss: 0.4870 - accuracy: 0.7695 - val_loss: 0.5476 - val_accuracy: 0.7081\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 31s 985ms/step - loss: 0.4475 - accuracy: 0.7956 - val_loss: 0.5914 - val_accuracy: 0.7278\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 31s 973ms/step - loss: 0.4139 - accuracy: 0.8128 - val_loss: 0.5292 - val_accuracy: 0.7318\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 30s 952ms/step - loss: 0.3742 - accuracy: 0.8300 - val_loss: 0.6366 - val_accuracy: 0.7160\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 30s 953ms/step - loss: 0.3778 - accuracy: 0.8222 - val_loss: 0.5504 - val_accuracy: 0.7278\n",
      "16/16 [==============================] - 3s 199ms/step\n",
      "0.7051798174986581\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 42s 1s/step - loss: 0.6350 - accuracy: 0.6596 - val_loss: 0.6922 - val_accuracy: 0.5464\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 39s 1s/step - loss: 0.5358 - accuracy: 0.7379 - val_loss: 0.5288 - val_accuracy: 0.7475\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 44s 1s/step - loss: 0.4841 - accuracy: 0.7700 - val_loss: 0.5466 - val_accuracy: 0.7120\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 36s 1s/step - loss: 0.4444 - accuracy: 0.7966 - val_loss: 0.5781 - val_accuracy: 0.7298\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 36s 1s/step - loss: 0.4101 - accuracy: 0.8153 - val_loss: 0.5652 - val_accuracy: 0.7239\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 37s 1s/step - loss: 0.3752 - accuracy: 0.8291 - val_loss: 0.6695 - val_accuracy: 0.7179\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 36s 1s/step - loss: 0.3738 - accuracy: 0.8276 - val_loss: 0.5541 - val_accuracy: 0.7239\n",
      "16/16 [==============================] - 5s 288ms/step\n",
      "0.7115835881390884\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.6623 - accuracy: 0.5936 - val_loss: 0.6574 - val_accuracy: 0.6588\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.5689 - accuracy: 0.7108 - val_loss: 0.5482 - val_accuracy: 0.7475\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 31s 968ms/step - loss: 0.4993 - accuracy: 0.7616 - val_loss: 0.5277 - val_accuracy: 0.7219\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 36s 1s/step - loss: 0.4495 - accuracy: 0.7916 - val_loss: 0.5652 - val_accuracy: 0.7318\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.4151 - accuracy: 0.8118 - val_loss: 0.5191 - val_accuracy: 0.7318\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 32s 1s/step - loss: 0.3801 - accuracy: 0.8266 - val_loss: 0.6204 - val_accuracy: 0.7140\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 31s 978ms/step - loss: 0.3731 - accuracy: 0.8251 - val_loss: 0.5584 - val_accuracy: 0.7258\n",
      "16/16 [==============================] - 3s 201ms/step\n",
      "0.7067881153762741\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 41s 1s/step - loss: 0.6384 - accuracy: 0.6547 - val_loss: 0.6737 - val_accuracy: 0.5641\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 43s 1s/step - loss: 0.5375 - accuracy: 0.7374 - val_loss: 0.5289 - val_accuracy: 0.7436\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 37s 1s/step - loss: 0.4862 - accuracy: 0.7680 - val_loss: 0.5502 - val_accuracy: 0.7160\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 37s 1s/step - loss: 0.4460 - accuracy: 0.7975 - val_loss: 0.5817 - val_accuracy: 0.7318\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 38s 1s/step - loss: 0.4104 - accuracy: 0.8138 - val_loss: 0.5701 - val_accuracy: 0.7219\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 36s 1s/step - loss: 0.3735 - accuracy: 0.8286 - val_loss: 0.5806 - val_accuracy: 0.7337\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 37s 1s/step - loss: 0.3765 - accuracy: 0.8251 - val_loss: 0.5582 - val_accuracy: 0.7199\n",
      "16/16 [==============================] - 5s 288ms/step\n",
      "0.7070770817037617\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 36s 1s/step - loss: 0.6347 - accuracy: 0.6532 - val_loss: 0.6710 - val_accuracy: 0.5661\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.5286 - accuracy: 0.7443 - val_loss: 0.5298 - val_accuracy: 0.7594\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 32s 989ms/step - loss: 0.4820 - accuracy: 0.7749 - val_loss: 0.5422 - val_accuracy: 0.7199\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 32s 996ms/step - loss: 0.4373 - accuracy: 0.8034 - val_loss: 0.5913 - val_accuracy: 0.7298\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 32s 1s/step - loss: 0.3985 - accuracy: 0.8222 - val_loss: 0.5742 - val_accuracy: 0.7278\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 32s 1s/step - loss: 0.3730 - accuracy: 0.8246 - val_loss: 0.6385 - val_accuracy: 0.7179\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 31s 989ms/step - loss: 0.3605 - accuracy: 0.8300 - val_loss: 0.5694 - val_accuracy: 0.7199\n",
      "16/16 [==============================] - 4s 230ms/step\n",
      "0.7224087171938391\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 37s 1s/step - loss: 0.6395 - accuracy: 0.6507 - val_loss: 0.6659 - val_accuracy: 0.5720\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 37s 1s/step - loss: 0.5461 - accuracy: 0.7330 - val_loss: 0.5384 - val_accuracy: 0.7456\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 36s 1s/step - loss: 0.4955 - accuracy: 0.7645 - val_loss: 0.5346 - val_accuracy: 0.7199\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.4479 - accuracy: 0.7975 - val_loss: 0.5825 - val_accuracy: 0.7298\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.4119 - accuracy: 0.8108 - val_loss: 0.5707 - val_accuracy: 0.7278\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 36s 1s/step - loss: 0.3814 - accuracy: 0.8271 - val_loss: 0.6890 - val_accuracy: 0.7160\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 36s 1s/step - loss: 0.3740 - accuracy: 0.8271 - val_loss: 0.5556 - val_accuracy: 0.7219\n",
      "16/16 [==============================] - 4s 264ms/step\n",
      "0.7049998872375454\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.6402 - accuracy: 0.6581 - val_loss: 0.6842 - val_accuracy: 0.5562\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 36s 1s/step - loss: 0.5368 - accuracy: 0.7379 - val_loss: 0.5274 - val_accuracy: 0.7475\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 40s 1s/step - loss: 0.4875 - accuracy: 0.7660 - val_loss: 0.5430 - val_accuracy: 0.7140\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.4446 - accuracy: 0.7985 - val_loss: 0.5854 - val_accuracy: 0.7278\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 30s 950ms/step - loss: 0.4109 - accuracy: 0.8153 - val_loss: 0.5432 - val_accuracy: 0.7278\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 30s 948ms/step - loss: 0.3735 - accuracy: 0.8296 - val_loss: 0.6213 - val_accuracy: 0.7199\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 30s 927ms/step - loss: 0.3759 - accuracy: 0.8286 - val_loss: 0.5527 - val_accuracy: 0.7258\n",
      "16/16 [==============================] - 3s 194ms/step\n",
      "0.7133872734339116\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.6314 - accuracy: 0.6562 - val_loss: 0.6803 - val_accuracy: 0.5464\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.5316 - accuracy: 0.7429 - val_loss: 0.5263 - val_accuracy: 0.7495\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 32s 988ms/step - loss: 0.4832 - accuracy: 0.7744 - val_loss: 0.5444 - val_accuracy: 0.7160\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 31s 981ms/step - loss: 0.4419 - accuracy: 0.7970 - val_loss: 0.5903 - val_accuracy: 0.7258\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 32s 1s/step - loss: 0.4055 - accuracy: 0.8153 - val_loss: 0.5793 - val_accuracy: 0.7219\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 32s 995ms/step - loss: 0.3710 - accuracy: 0.8315 - val_loss: 0.6160 - val_accuracy: 0.7278\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.3697 - accuracy: 0.8310 - val_loss: 0.5522 - val_accuracy: 0.7318\n",
      "16/16 [==============================] - 4s 244ms/step\n",
      "0.7133795387471122\n",
      "0.7106732176713042\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(r\"C:\\Users\\alici\\Documents\\tcc\\v3\\particoes\\blogsetbr\\houdout\\train.csv\")\n",
    "df_test = pd.read_csv(r\"C:\\Users\\alici\\Documents\\tcc\\v3\\particoes\\blogsetbr\\houdout\\test.csv\")\n",
    "\n",
    "gender = []\n",
    "for _ in range(10):\n",
    "    X_train = df_train[\"Texts\"].apply(clean_text).to_numpy()\n",
    "    X_test = df_test[\"Texts\"].apply(clean_text).to_numpy()\n",
    "    y_train_gender = df_train[\"GenderClass\"].to_numpy()\n",
    "    y_test_gender = df_test[\"GenderClass\"].to_numpy()\n",
    "\n",
    "    num_words = []\n",
    "    for text in (X_train.tolist()+X_test.tolist()):\n",
    "        num_words.append(len(text.split()))\n",
    "\n",
    "    mean = sum(num_words)//len(num_words)\n",
    "\n",
    "    train_texts = X_train.tolist()\n",
    "    test_texts = X_test.tolist()\n",
    "\n",
    "    tfidfvec = TfidfVectorizer(max_features = mean, max_df=0.9)\n",
    "    tfidfvec.fit(train_texts)\n",
    "    tfidf_train = tfidfvec.transform(train_texts).toarray()\n",
    "    tfidf_test = tfidfvec.transform(test_texts).toarray()\n",
    "\n",
    "    X_train = tfidf_train.reshape(tfidf_train.shape[0],tfidf_train.shape[1],1)\n",
    "    X_test = tfidf_test.reshape(tfidf_test.shape[0],tfidf_test.shape[1],1)\n",
    "\n",
    "    y_train_gander_cat = keras.utils.to_categorical(y_train_gender,num_classes=2)\n",
    "    y_test_gender_cat = keras.utils.to_categorical(y_test_gender,num_classes=2)\n",
    "\n",
    "    size = X_test.shape[1]\n",
    "\n",
    "    model_gender = create_model_gender(param[\"gender\"][\"params\"][\"filters\"], \n",
    "                                        kernel_size=param[\"gender\"][\"params\"][\"kernel_size\"], \n",
    "                                        strides=param[\"gender\"][\"params\"][\"strides\"], \n",
    "                                        dropout_rate=param[\"gender\"][\"params\"][\"dropout_rate\"], \n",
    "                                        pool_size=param[\"gender\"][\"params\"][\"pool_size\"], \n",
    "                                        dense_units=512, \n",
    "                                        max_len=size)\n",
    "\n",
    "    callback = [\n",
    "        EarlyStopping(patience=5, monitor='val_accuracy', mode='max', restore_best_weights=True),\n",
    "    ]\n",
    "    model_gender.fit(X_train, y_train_gander_cat,\n",
    "                    validation_data=(X_test,y_test_gender_cat), \n",
    "                    batch_size=param[\"gender\"][\"params\"][\"batch_size\"],\n",
    "                    epochs=param[\"gender\"][\"params\"][\"epochs\"],\n",
    "                    callbacks=callback)\n",
    "\n",
    "    y_pred_gender = model_gender.predict(\n",
    "        X_test\n",
    "    )\n",
    "\n",
    "    y_pred_list_gender = [np.argmax(x, axis=-1) for x in y_pred_gender]\n",
    "\n",
    "    df_test[\"PredictGender\"] = y_pred_list_gender\n",
    "    print(metrics.f1_score(y_test_gender, y_pred_list_gender, average='macro'))\n",
    "    gender.append(metrics.f1_score(y_test_gender, y_pred_list_gender, average='macro'))\n",
    "\n",
    "print(sum(gender)/len(gender))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.6391 - accuracy: 0.6547 - val_loss: 0.6865 - val_accuracy: 0.5444\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 36s 1s/step - loss: 0.5298 - accuracy: 0.7458 - val_loss: 0.5253 - val_accuracy: 0.7495\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.4816 - accuracy: 0.7744 - val_loss: 0.5425 - val_accuracy: 0.7160\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.4398 - accuracy: 0.8005 - val_loss: 0.5793 - val_accuracy: 0.7258\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.4049 - accuracy: 0.8177 - val_loss: 0.5586 - val_accuracy: 0.7239\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.3670 - accuracy: 0.8365 - val_loss: 0.5890 - val_accuracy: 0.7258\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.3700 - accuracy: 0.8315 - val_loss: 0.5506 - val_accuracy: 0.7298\n",
      "16/16 [==============================] - 4s 235ms/step\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 15s 223ms/step - loss: 1.0817 - accuracy: 0.3980 - val_loss: 1.0671 - val_accuracy: 0.4142\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 14s 220ms/step - loss: 1.0405 - accuracy: 0.4493 - val_loss: 1.1307 - val_accuracy: 0.3984\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 14s 214ms/step - loss: 0.9864 - accuracy: 0.5113 - val_loss: 1.0519 - val_accuracy: 0.4043\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 14s 212ms/step - loss: 0.9236 - accuracy: 0.5571 - val_loss: 1.0911 - val_accuracy: 0.4359\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 14s 214ms/step - loss: 0.8825 - accuracy: 0.5778 - val_loss: 1.1168 - val_accuracy: 0.4398\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 14s 213ms/step - loss: 0.8370 - accuracy: 0.5985 - val_loss: 1.0880 - val_accuracy: 0.4497\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 14s 213ms/step - loss: 0.7816 - accuracy: 0.6404 - val_loss: 1.1325 - val_accuracy: 0.4497\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 14s 213ms/step - loss: 0.7196 - accuracy: 0.6764 - val_loss: 1.2504 - val_accuracy: 0.4576\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 14s 215ms/step - loss: 0.6684 - accuracy: 0.7025 - val_loss: 1.2906 - val_accuracy: 0.4260\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 14s 213ms/step - loss: 0.6127 - accuracy: 0.7281 - val_loss: 1.3077 - val_accuracy: 0.4379\n",
      "16/16 [==============================] - 1s 60ms/step\n",
      "juntos: 0.4147901838067996\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 1.0835 - accuracy: 0.4150 - val_loss: 1.0540 - val_accuracy: 0.5294\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 1.0152 - accuracy: 0.5074 - val_loss: 0.9735 - val_accuracy: 0.4790\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 6s 214ms/step - loss: 0.9411 - accuracy: 0.5333 - val_loss: 1.0028 - val_accuracy: 0.5294\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 6s 235ms/step - loss: 0.8767 - accuracy: 0.5850 - val_loss: 1.0031 - val_accuracy: 0.4706\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 7s 274ms/step - loss: 0.8086 - accuracy: 0.6207 - val_loss: 1.0897 - val_accuracy: 0.4874\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 6s 213ms/step - loss: 0.7404 - accuracy: 0.6724 - val_loss: 1.0671 - val_accuracy: 0.5294\n",
      "4/4 [==============================] - 0s 27ms/step\n",
      "fem: 0.5140594699418229\n",
      "Epoch 1/10\n",
      "39/39 [==============================] - 26s 658ms/step - loss: 1.0746 - accuracy: 0.4007 - val_loss: 1.0476 - val_accuracy: 0.4253\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 26s 672ms/step - loss: 1.0067 - accuracy: 0.4787 - val_loss: 1.0393 - val_accuracy: 0.4304\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 25s 655ms/step - loss: 0.9323 - accuracy: 0.5583 - val_loss: 1.1278 - val_accuracy: 0.3686\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 25s 655ms/step - loss: 0.8313 - accuracy: 0.6084 - val_loss: 1.1055 - val_accuracy: 0.4356\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 29s 743ms/step - loss: 0.7098 - accuracy: 0.6921 - val_loss: 1.1761 - val_accuracy: 0.4562\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 24s 610ms/step - loss: 0.6629 - accuracy: 0.7020 - val_loss: 1.5091 - val_accuracy: 0.4098\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 26s 656ms/step - loss: 0.5805 - accuracy: 0.7479 - val_loss: 1.3532 - val_accuracy: 0.4098\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 25s 635ms/step - loss: 0.4642 - accuracy: 0.8054 - val_loss: 1.6020 - val_accuracy: 0.4046\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 26s 665ms/step - loss: 0.4187 - accuracy: 0.8300 - val_loss: 1.7814 - val_accuracy: 0.4304\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - 25s 654ms/step - loss: 0.3813 - accuracy: 0.8366 - val_loss: 1.5971 - val_accuracy: 0.4175\n",
      "13/13 [==============================] - 1s 96ms/step\n",
      "masc: 0.430296951501362\n",
      "separado: 0.45787283122953587\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 27s 845ms/step - loss: 0.6439 - accuracy: 0.6576 - val_loss: 0.6655 - val_accuracy: 0.5700\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 27s 844ms/step - loss: 0.5379 - accuracy: 0.7419 - val_loss: 0.5310 - val_accuracy: 0.7436\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 27s 831ms/step - loss: 0.4876 - accuracy: 0.7685 - val_loss: 0.5450 - val_accuracy: 0.7179\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 28s 884ms/step - loss: 0.4460 - accuracy: 0.7951 - val_loss: 0.5768 - val_accuracy: 0.7298\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 29s 890ms/step - loss: 0.4100 - accuracy: 0.8153 - val_loss: 0.5672 - val_accuracy: 0.7239\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 25s 777ms/step - loss: 0.3783 - accuracy: 0.8246 - val_loss: 0.5935 - val_accuracy: 0.7298\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 25s 792ms/step - loss: 0.3763 - accuracy: 0.8271 - val_loss: 0.5512 - val_accuracy: 0.7258\n",
      "16/16 [==============================] - 2s 100ms/step\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 12s 174ms/step - loss: 1.0808 - accuracy: 0.3980 - val_loss: 1.0651 - val_accuracy: 0.4162\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 11s 167ms/step - loss: 1.0400 - accuracy: 0.4365 - val_loss: 1.1134 - val_accuracy: 0.4063\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 11s 172ms/step - loss: 0.9842 - accuracy: 0.5103 - val_loss: 1.0595 - val_accuracy: 0.4181\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 10s 163ms/step - loss: 0.9289 - accuracy: 0.5345 - val_loss: 1.0756 - val_accuracy: 0.4379\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 0.8891 - accuracy: 0.5744 - val_loss: 1.1017 - val_accuracy: 0.4517\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 10s 160ms/step - loss: 0.8449 - accuracy: 0.6000 - val_loss: 1.0933 - val_accuracy: 0.4438\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 11s 179ms/step - loss: 0.7906 - accuracy: 0.6350 - val_loss: 1.1371 - val_accuracy: 0.4675\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 0.7369 - accuracy: 0.6675 - val_loss: 1.2556 - val_accuracy: 0.4615\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 10s 160ms/step - loss: 0.6880 - accuracy: 0.6857 - val_loss: 1.2754 - val_accuracy: 0.4103\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 0.6299 - accuracy: 0.7118 - val_loss: 1.3111 - val_accuracy: 0.4398\n",
      "16/16 [==============================] - 1s 39ms/step\n",
      "juntos: 0.4208521789020385\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 6s 213ms/step - loss: 1.0842 - accuracy: 0.4187 - val_loss: 1.0474 - val_accuracy: 0.5242\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 6s 215ms/step - loss: 1.0048 - accuracy: 0.5234 - val_loss: 0.9580 - val_accuracy: 0.5161\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 6s 231ms/step - loss: 0.9304 - accuracy: 0.5283 - val_loss: 0.9739 - val_accuracy: 0.5726\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 6s 224ms/step - loss: 0.8598 - accuracy: 0.6010 - val_loss: 0.9643 - val_accuracy: 0.5403\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 6s 229ms/step - loss: 0.7847 - accuracy: 0.6515 - val_loss: 1.0112 - val_accuracy: 0.5323\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 6s 235ms/step - loss: 0.7355 - accuracy: 0.6564 - val_loss: 1.0131 - val_accuracy: 0.5484\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 6s 246ms/step - loss: 0.6749 - accuracy: 0.7081 - val_loss: 1.0489 - val_accuracy: 0.5565\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 6s 246ms/step - loss: 0.6491 - accuracy: 0.7291 - val_loss: 1.1460 - val_accuracy: 0.5484\n",
      "4/4 [==============================] - 0s 48ms/step\n",
      "fem: 0.5644910071010211\n",
      "Epoch 1/10\n",
      "39/39 [==============================] - 27s 669ms/step - loss: 1.0762 - accuracy: 0.3949 - val_loss: 1.0485 - val_accuracy: 0.4256\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 25s 646ms/step - loss: 1.0071 - accuracy: 0.4721 - val_loss: 1.0452 - val_accuracy: 0.4256\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 24s 625ms/step - loss: 0.9308 - accuracy: 0.5591 - val_loss: 1.0790 - val_accuracy: 0.3786\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 24s 627ms/step - loss: 0.8162 - accuracy: 0.6215 - val_loss: 1.1240 - val_accuracy: 0.4334\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 24s 626ms/step - loss: 0.7070 - accuracy: 0.7020 - val_loss: 1.2332 - val_accuracy: 0.4517\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 25s 634ms/step - loss: 0.6605 - accuracy: 0.7192 - val_loss: 1.4692 - val_accuracy: 0.4047\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 24s 620ms/step - loss: 0.5706 - accuracy: 0.7627 - val_loss: 1.4591 - val_accuracy: 0.4256\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 25s 636ms/step - loss: 0.4406 - accuracy: 0.8251 - val_loss: 1.7751 - val_accuracy: 0.3916\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 24s 624ms/step - loss: 0.4228 - accuracy: 0.8309 - val_loss: 1.6435 - val_accuracy: 0.4256\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - 24s 628ms/step - loss: 0.3621 - accuracy: 0.8399 - val_loss: 1.5879 - val_accuracy: 0.4230\n",
      "12/12 [==============================] - 1s 93ms/step\n",
      "masc: 0.4391006251260335\n",
      "separado: 0.46828827080366825\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 29s 892ms/step - loss: 0.6435 - accuracy: 0.6502 - val_loss: 0.7618 - val_accuracy: 0.4576\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 26s 801ms/step - loss: 0.5424 - accuracy: 0.7320 - val_loss: 0.5287 - val_accuracy: 0.7475\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 23s 720ms/step - loss: 0.4878 - accuracy: 0.7690 - val_loss: 0.5402 - val_accuracy: 0.7179\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 23s 719ms/step - loss: 0.4455 - accuracy: 0.7995 - val_loss: 0.5771 - val_accuracy: 0.7318\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 23s 718ms/step - loss: 0.4088 - accuracy: 0.8138 - val_loss: 0.5395 - val_accuracy: 0.7318\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 23s 718ms/step - loss: 0.3805 - accuracy: 0.8251 - val_loss: 0.6456 - val_accuracy: 0.7179\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 23s 710ms/step - loss: 0.3749 - accuracy: 0.8251 - val_loss: 0.5546 - val_accuracy: 0.7258\n",
      "16/16 [==============================] - 1s 81ms/step\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 12s 163ms/step - loss: 1.0792 - accuracy: 0.3946 - val_loss: 1.0621 - val_accuracy: 0.4024\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 11s 170ms/step - loss: 1.0378 - accuracy: 0.4527 - val_loss: 1.1394 - val_accuracy: 0.3688\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 11s 177ms/step - loss: 0.9816 - accuracy: 0.5118 - val_loss: 1.0635 - val_accuracy: 0.3945\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 11s 175ms/step - loss: 0.9334 - accuracy: 0.5453 - val_loss: 1.0806 - val_accuracy: 0.4418\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 11s 172ms/step - loss: 0.8945 - accuracy: 0.5680 - val_loss: 1.0841 - val_accuracy: 0.4615\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 11s 164ms/step - loss: 0.8485 - accuracy: 0.6034 - val_loss: 1.0794 - val_accuracy: 0.4477\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 10s 160ms/step - loss: 0.7981 - accuracy: 0.6271 - val_loss: 1.1233 - val_accuracy: 0.4320\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 10s 157ms/step - loss: 0.7350 - accuracy: 0.6704 - val_loss: 1.2528 - val_accuracy: 0.4635\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 10s 159ms/step - loss: 0.6968 - accuracy: 0.6793 - val_loss: 1.2690 - val_accuracy: 0.4201\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 11s 167ms/step - loss: 0.6327 - accuracy: 0.7266 - val_loss: 1.2753 - val_accuracy: 0.4477\n",
      "16/16 [==============================] - 1s 28ms/step\n",
      "juntos: 0.4368178510793112\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 6s 213ms/step - loss: 1.0847 - accuracy: 0.4138 - val_loss: 1.0518 - val_accuracy: 0.5781\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 1.0084 - accuracy: 0.5062 - val_loss: 0.9713 - val_accuracy: 0.5234\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 6s 233ms/step - loss: 0.9363 - accuracy: 0.5369 - val_loss: 0.9714 - val_accuracy: 0.5469\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 6s 227ms/step - loss: 0.8625 - accuracy: 0.6096 - val_loss: 1.0076 - val_accuracy: 0.5078\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 6s 223ms/step - loss: 0.7984 - accuracy: 0.6195 - val_loss: 1.2332 - val_accuracy: 0.4297\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 6s 221ms/step - loss: 0.7466 - accuracy: 0.6478 - val_loss: 1.0893 - val_accuracy: 0.5156\n",
      "4/4 [==============================] - 0s 41ms/step\n",
      "fem: 0.5787811318800808\n",
      "Epoch 1/10\n",
      "39/39 [==============================] - 27s 697ms/step - loss: 1.0810 - accuracy: 0.3785 - val_loss: 1.0527 - val_accuracy: 0.4301\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 26s 667ms/step - loss: 1.0292 - accuracy: 0.4548 - val_loss: 1.0432 - val_accuracy: 0.4222\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 26s 669ms/step - loss: 0.9600 - accuracy: 0.5386 - val_loss: 1.0738 - val_accuracy: 0.3747\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 27s 695ms/step - loss: 0.8656 - accuracy: 0.5944 - val_loss: 1.0888 - val_accuracy: 0.4433\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 26s 656ms/step - loss: 0.7653 - accuracy: 0.6626 - val_loss: 1.1145 - val_accuracy: 0.4565\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 27s 682ms/step - loss: 0.7233 - accuracy: 0.6683 - val_loss: 1.5014 - val_accuracy: 0.4222\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 26s 678ms/step - loss: 0.6235 - accuracy: 0.7299 - val_loss: 1.3518 - val_accuracy: 0.4169\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 26s 658ms/step - loss: 0.5235 - accuracy: 0.7808 - val_loss: 1.5977 - val_accuracy: 0.3958\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 27s 694ms/step - loss: 0.4785 - accuracy: 0.7956 - val_loss: 1.4979 - val_accuracy: 0.4195\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - 26s 656ms/step - loss: 0.4052 - accuracy: 0.8251 - val_loss: 1.5032 - val_accuracy: 0.4327\n",
      "12/12 [==============================] - 2s 126ms/step\n",
      "masc: 0.42962152521566094\n",
      "separado: 0.4784829746178074\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 25s 781ms/step - loss: 0.6329 - accuracy: 0.6498 - val_loss: 0.6117 - val_accuracy: 0.6430\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 24s 760ms/step - loss: 0.5306 - accuracy: 0.7443 - val_loss: 0.5250 - val_accuracy: 0.7475\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 23s 727ms/step - loss: 0.4836 - accuracy: 0.7734 - val_loss: 0.5459 - val_accuracy: 0.7101\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 24s 751ms/step - loss: 0.4413 - accuracy: 0.7995 - val_loss: 0.5866 - val_accuracy: 0.7298\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 25s 781ms/step - loss: 0.4035 - accuracy: 0.8182 - val_loss: 0.5749 - val_accuracy: 0.7258\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 25s 772ms/step - loss: 0.3756 - accuracy: 0.8256 - val_loss: 0.6875 - val_accuracy: 0.7160\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 24s 752ms/step - loss: 0.3675 - accuracy: 0.8305 - val_loss: 0.5576 - val_accuracy: 0.7239\n",
      "16/16 [==============================] - 2s 87ms/step\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 1.0807 - accuracy: 0.4015 - val_loss: 1.0649 - val_accuracy: 0.4142\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 10s 158ms/step - loss: 1.0400 - accuracy: 0.4433 - val_loss: 1.1131 - val_accuracy: 0.3886\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 10s 160ms/step - loss: 0.9841 - accuracy: 0.5182 - val_loss: 1.0554 - val_accuracy: 0.4260\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 11s 172ms/step - loss: 0.9219 - accuracy: 0.5502 - val_loss: 1.0837 - val_accuracy: 0.4379\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 12s 184ms/step - loss: 0.8823 - accuracy: 0.5695 - val_loss: 1.0886 - val_accuracy: 0.4359\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 13s 202ms/step - loss: 0.8430 - accuracy: 0.5906 - val_loss: 1.0956 - val_accuracy: 0.4438\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 12s 183ms/step - loss: 0.7841 - accuracy: 0.6310 - val_loss: 1.1271 - val_accuracy: 0.4655\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 11s 169ms/step - loss: 0.7385 - accuracy: 0.6695 - val_loss: 1.2190 - val_accuracy: 0.4635\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 10s 155ms/step - loss: 0.6831 - accuracy: 0.6951 - val_loss: 1.3225 - val_accuracy: 0.4438\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 10s 150ms/step - loss: 0.6275 - accuracy: 0.7246 - val_loss: 1.3021 - val_accuracy: 0.4477\n",
      "16/16 [==============================] - 0s 23ms/step\n",
      "juntos: 0.42625455074996355\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 7s 252ms/step - loss: 1.0882 - accuracy: 0.4052 - val_loss: 1.0690 - val_accuracy: 0.4922\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 6s 217ms/step - loss: 1.0314 - accuracy: 0.4729 - val_loss: 0.9843 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 6s 214ms/step - loss: 0.9599 - accuracy: 0.5333 - val_loss: 0.9777 - val_accuracy: 0.4844\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 6s 214ms/step - loss: 0.8778 - accuracy: 0.6059 - val_loss: 1.0056 - val_accuracy: 0.4922\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 5s 209ms/step - loss: 0.8136 - accuracy: 0.6330 - val_loss: 1.0720 - val_accuracy: 0.4688\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 6s 213ms/step - loss: 0.7481 - accuracy: 0.6847 - val_loss: 1.0458 - val_accuracy: 0.5547\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.6921 - accuracy: 0.6995 - val_loss: 1.0478 - val_accuracy: 0.5156\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.6678 - accuracy: 0.6958 - val_loss: 1.1958 - val_accuracy: 0.4922\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.5941 - accuracy: 0.7562 - val_loss: 1.7030 - val_accuracy: 0.3672\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.5591 - accuracy: 0.7611 - val_loss: 1.3369 - val_accuracy: 0.4766\n",
      "4/4 [==============================] - 0s 35ms/step\n",
      "fem: 0.4266193853427896\n",
      "Epoch 1/10\n",
      "39/39 [==============================] - 29s 723ms/step - loss: 1.0708 - accuracy: 0.3949 - val_loss: 1.0417 - val_accuracy: 0.4354\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 28s 726ms/step - loss: 0.9871 - accuracy: 0.4770 - val_loss: 1.0586 - val_accuracy: 0.4195\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 27s 704ms/step - loss: 0.9026 - accuracy: 0.5829 - val_loss: 1.1221 - val_accuracy: 0.3720\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 28s 719ms/step - loss: 0.7904 - accuracy: 0.6453 - val_loss: 1.1332 - val_accuracy: 0.4380\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 28s 716ms/step - loss: 0.6638 - accuracy: 0.7200 - val_loss: 1.2257 - val_accuracy: 0.4380\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 27s 700ms/step - loss: 0.6222 - accuracy: 0.7348 - val_loss: 1.7080 - val_accuracy: 0.4063\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 29s 746ms/step - loss: 0.5212 - accuracy: 0.7767 - val_loss: 1.4856 - val_accuracy: 0.4274\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 26s 668ms/step - loss: 0.4105 - accuracy: 0.8317 - val_loss: 1.7082 - val_accuracy: 0.4090\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 26s 662ms/step - loss: 0.3634 - accuracy: 0.8489 - val_loss: 1.7525 - val_accuracy: 0.4380\n",
      "12/12 [==============================] - 2s 131ms/step\n",
      "masc: 0.40793763288447904\n",
      "separado: 0.43144703315736005\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 27s 838ms/step - loss: 0.6356 - accuracy: 0.6695 - val_loss: 0.6476 - val_accuracy: 0.6055\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 29s 921ms/step - loss: 0.5316 - accuracy: 0.7433 - val_loss: 0.5269 - val_accuracy: 0.7535\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 26s 798ms/step - loss: 0.4833 - accuracy: 0.7700 - val_loss: 0.5489 - val_accuracy: 0.7140\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 25s 769ms/step - loss: 0.4433 - accuracy: 0.7975 - val_loss: 0.5833 - val_accuracy: 0.7298\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 25s 796ms/step - loss: 0.4029 - accuracy: 0.8172 - val_loss: 0.5586 - val_accuracy: 0.7337\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 25s 772ms/step - loss: 0.3774 - accuracy: 0.8232 - val_loss: 0.6417 - val_accuracy: 0.7160\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 25s 787ms/step - loss: 0.3689 - accuracy: 0.8291 - val_loss: 0.5626 - val_accuracy: 0.7239\n",
      "16/16 [==============================] - 2s 117ms/step\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 12s 181ms/step - loss: 1.0790 - accuracy: 0.3951 - val_loss: 1.0626 - val_accuracy: 0.4162\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 11s 172ms/step - loss: 1.0382 - accuracy: 0.4458 - val_loss: 1.1019 - val_accuracy: 0.3945\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 11s 170ms/step - loss: 0.9778 - accuracy: 0.5217 - val_loss: 1.0662 - val_accuracy: 0.3984\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 11s 178ms/step - loss: 0.9252 - accuracy: 0.5483 - val_loss: 1.0877 - val_accuracy: 0.4497\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 11s 175ms/step - loss: 0.8835 - accuracy: 0.5778 - val_loss: 1.1288 - val_accuracy: 0.4359\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 12s 182ms/step - loss: 0.8396 - accuracy: 0.5990 - val_loss: 1.0797 - val_accuracy: 0.4615\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 11s 176ms/step - loss: 0.7778 - accuracy: 0.6473 - val_loss: 1.1422 - val_accuracy: 0.4635\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 11s 173ms/step - loss: 0.7234 - accuracy: 0.6773 - val_loss: 1.2333 - val_accuracy: 0.4714\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 11s 179ms/step - loss: 0.6737 - accuracy: 0.7000 - val_loss: 1.3343 - val_accuracy: 0.4162\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 11s 174ms/step - loss: 0.6093 - accuracy: 0.7330 - val_loss: 1.2823 - val_accuracy: 0.4596\n",
      "16/16 [==============================] - 1s 38ms/step\n",
      "juntos: 0.45351835577399485\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 6s 227ms/step - loss: 1.0893 - accuracy: 0.3879 - val_loss: 1.0744 - val_accuracy: 0.4298\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 6s 228ms/step - loss: 1.0369 - accuracy: 0.4680 - val_loss: 0.9921 - val_accuracy: 0.4793\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 6s 237ms/step - loss: 0.9761 - accuracy: 0.5185 - val_loss: 0.9912 - val_accuracy: 0.5207\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 7s 263ms/step - loss: 0.8978 - accuracy: 0.5961 - val_loss: 1.0105 - val_accuracy: 0.4628\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 6s 248ms/step - loss: 0.8293 - accuracy: 0.6404 - val_loss: 1.1730 - val_accuracy: 0.4380\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 6s 212ms/step - loss: 0.7730 - accuracy: 0.6687 - val_loss: 1.0397 - val_accuracy: 0.4876\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 6s 225ms/step - loss: 0.7127 - accuracy: 0.6847 - val_loss: 1.0972 - val_accuracy: 0.4793\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 5s 210ms/step - loss: 0.6806 - accuracy: 0.7143 - val_loss: 1.1649 - val_accuracy: 0.4545\n",
      "4/4 [==============================] - 0s 36ms/step\n",
      "fem: 0.46072092159048683\n",
      "Epoch 1/10\n",
      "39/39 [==============================] - 28s 695ms/step - loss: 1.0755 - accuracy: 0.3908 - val_loss: 1.0475 - val_accuracy: 0.4275\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 27s 686ms/step - loss: 1.0034 - accuracy: 0.4663 - val_loss: 1.0381 - val_accuracy: 0.4275\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 27s 682ms/step - loss: 0.9253 - accuracy: 0.5599 - val_loss: 1.1562 - val_accuracy: 0.3472\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 27s 706ms/step - loss: 0.8251 - accuracy: 0.6314 - val_loss: 1.1140 - val_accuracy: 0.4534\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 26s 674ms/step - loss: 0.6973 - accuracy: 0.6913 - val_loss: 1.1895 - val_accuracy: 0.4508\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 27s 693ms/step - loss: 0.6575 - accuracy: 0.7036 - val_loss: 1.4760 - val_accuracy: 0.4223\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 27s 702ms/step - loss: 0.5615 - accuracy: 0.7652 - val_loss: 1.4418 - val_accuracy: 0.3964\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 26s 672ms/step - loss: 0.4547 - accuracy: 0.8144 - val_loss: 1.6855 - val_accuracy: 0.4067\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 26s 672ms/step - loss: 0.4114 - accuracy: 0.8342 - val_loss: 1.9180 - val_accuracy: 0.4326\n",
      "13/13 [==============================] - 2s 148ms/step\n",
      "masc: 0.42559382613556346\n",
      "separado: 0.4483401126377203\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 27s 831ms/step - loss: 0.6359 - accuracy: 0.6512 - val_loss: 0.6576 - val_accuracy: 0.5858\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 27s 842ms/step - loss: 0.5325 - accuracy: 0.7379 - val_loss: 0.5285 - val_accuracy: 0.7475\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 27s 844ms/step - loss: 0.4827 - accuracy: 0.7778 - val_loss: 0.5423 - val_accuracy: 0.7120\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 27s 835ms/step - loss: 0.4416 - accuracy: 0.8015 - val_loss: 0.5865 - val_accuracy: 0.7298\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 27s 860ms/step - loss: 0.4048 - accuracy: 0.8172 - val_loss: 0.5709 - val_accuracy: 0.7239\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 27s 834ms/step - loss: 0.3743 - accuracy: 0.8261 - val_loss: 0.5972 - val_accuracy: 0.7239\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 25s 782ms/step - loss: 0.3696 - accuracy: 0.8296 - val_loss: 0.5570 - val_accuracy: 0.7239\n",
      "16/16 [==============================] - 2s 127ms/step\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 1.0805 - accuracy: 0.3966 - val_loss: 1.0658 - val_accuracy: 0.4122\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 10s 163ms/step - loss: 1.0410 - accuracy: 0.4498 - val_loss: 1.1339 - val_accuracy: 0.3807\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 0.9846 - accuracy: 0.5094 - val_loss: 1.0529 - val_accuracy: 0.4142\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 10s 163ms/step - loss: 0.9305 - accuracy: 0.5557 - val_loss: 1.0847 - val_accuracy: 0.4418\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 10s 162ms/step - loss: 0.8884 - accuracy: 0.5562 - val_loss: 1.0977 - val_accuracy: 0.4379\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 10s 164ms/step - loss: 0.8455 - accuracy: 0.6005 - val_loss: 1.0814 - val_accuracy: 0.4418\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 10s 164ms/step - loss: 0.7794 - accuracy: 0.6493 - val_loss: 1.1312 - val_accuracy: 0.4615\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 0.7191 - accuracy: 0.6808 - val_loss: 1.2380 - val_accuracy: 0.4675\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 10s 163ms/step - loss: 0.6771 - accuracy: 0.7034 - val_loss: 1.2559 - val_accuracy: 0.4181\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 11s 168ms/step - loss: 0.6293 - accuracy: 0.7227 - val_loss: 1.2879 - val_accuracy: 0.4497\n",
      "16/16 [==============================] - 1s 35ms/step\n",
      "juntos: 0.43239552378124246\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 6s 228ms/step - loss: 1.0889 - accuracy: 0.4150 - val_loss: 1.0631 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 6s 229ms/step - loss: 1.0155 - accuracy: 0.4938 - val_loss: 0.9730 - val_accuracy: 0.5169\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 6s 228ms/step - loss: 0.9399 - accuracy: 0.5431 - val_loss: 0.9900 - val_accuracy: 0.4831\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 6s 225ms/step - loss: 0.8644 - accuracy: 0.5874 - val_loss: 0.9926 - val_accuracy: 0.4915\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 6s 225ms/step - loss: 0.7898 - accuracy: 0.6429 - val_loss: 1.2160 - val_accuracy: 0.4492\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 6s 225ms/step - loss: 0.7264 - accuracy: 0.6786 - val_loss: 1.0888 - val_accuracy: 0.4831\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 6s 226ms/step - loss: 0.6707 - accuracy: 0.7069 - val_loss: 1.1030 - val_accuracy: 0.4492\n",
      "4/4 [==============================] - 0s 49ms/step\n",
      "fem: 0.4817460317460318\n",
      "Epoch 1/10\n",
      "39/39 [==============================] - 26s 665ms/step - loss: 1.0794 - accuracy: 0.3883 - val_loss: 1.0486 - val_accuracy: 0.4447\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 25s 647ms/step - loss: 1.0205 - accuracy: 0.4557 - val_loss: 1.0389 - val_accuracy: 0.4216\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 24s 623ms/step - loss: 0.9496 - accuracy: 0.5419 - val_loss: 1.1090 - val_accuracy: 0.3728\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 23s 600ms/step - loss: 0.8444 - accuracy: 0.6100 - val_loss: 1.1228 - val_accuracy: 0.4370\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 23s 603ms/step - loss: 0.7358 - accuracy: 0.6880 - val_loss: 1.1462 - val_accuracy: 0.4396\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 24s 605ms/step - loss: 0.6881 - accuracy: 0.6946 - val_loss: 1.4669 - val_accuracy: 0.4113\n",
      "13/13 [==============================] - 1s 89ms/step\n",
      "masc: 0.33723662427788254\n",
      "separado: 0.4238602783837684\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 30s 921ms/step - loss: 0.6306 - accuracy: 0.6611 - val_loss: 0.7227 - val_accuracy: 0.5128\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 26s 821ms/step - loss: 0.5349 - accuracy: 0.7399 - val_loss: 0.5235 - val_accuracy: 0.7377\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 25s 774ms/step - loss: 0.4826 - accuracy: 0.7734 - val_loss: 0.5492 - val_accuracy: 0.7081\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 24s 766ms/step - loss: 0.4407 - accuracy: 0.7990 - val_loss: 0.5780 - val_accuracy: 0.7318\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 25s 771ms/step - loss: 0.4022 - accuracy: 0.8202 - val_loss: 0.5835 - val_accuracy: 0.7239\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 24s 759ms/step - loss: 0.3699 - accuracy: 0.8296 - val_loss: 0.6185 - val_accuracy: 0.7199\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 26s 808ms/step - loss: 0.3647 - accuracy: 0.8286 - val_loss: 0.5667 - val_accuracy: 0.7258\n",
      "16/16 [==============================] - 2s 122ms/step\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 12s 177ms/step - loss: 1.0813 - accuracy: 0.3961 - val_loss: 1.0647 - val_accuracy: 0.4221\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 11s 168ms/step - loss: 1.0416 - accuracy: 0.4502 - val_loss: 1.1202 - val_accuracy: 0.3846\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 12s 181ms/step - loss: 0.9822 - accuracy: 0.5099 - val_loss: 1.0720 - val_accuracy: 0.4280\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 11s 171ms/step - loss: 0.9303 - accuracy: 0.5458 - val_loss: 1.0799 - val_accuracy: 0.4477\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 11s 172ms/step - loss: 0.8921 - accuracy: 0.5690 - val_loss: 1.0893 - val_accuracy: 0.4438\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 10s 162ms/step - loss: 0.8373 - accuracy: 0.6034 - val_loss: 1.0822 - val_accuracy: 0.4477\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 0.7903 - accuracy: 0.6350 - val_loss: 1.1268 - val_accuracy: 0.4497\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 0.7290 - accuracy: 0.6724 - val_loss: 1.1999 - val_accuracy: 0.4813\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 11s 168ms/step - loss: 0.6842 - accuracy: 0.6916 - val_loss: 1.2461 - val_accuracy: 0.4280\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 11s 172ms/step - loss: 0.6284 - accuracy: 0.7158 - val_loss: 1.2719 - val_accuracy: 0.4517\n",
      "16/16 [==============================] - 1s 38ms/step\n",
      "juntos: 0.43375514895018324\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 6s 236ms/step - loss: 1.0862 - accuracy: 0.4101 - val_loss: 1.0631 - val_accuracy: 0.5319\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 6s 229ms/step - loss: 1.0092 - accuracy: 0.5135 - val_loss: 0.9832 - val_accuracy: 0.5106\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 6s 226ms/step - loss: 0.9285 - accuracy: 0.5554 - val_loss: 0.9965 - val_accuracy: 0.4965\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 6s 224ms/step - loss: 0.8559 - accuracy: 0.6022 - val_loss: 1.0155 - val_accuracy: 0.4752\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 6s 224ms/step - loss: 0.7921 - accuracy: 0.6515 - val_loss: 1.0817 - val_accuracy: 0.4823\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 6s 226ms/step - loss: 0.7279 - accuracy: 0.6700 - val_loss: 1.0445 - val_accuracy: 0.5106\n",
      "5/5 [==============================] - 0s 46ms/step\n",
      "fem: 0.5297146219476316\n",
      "Epoch 1/10\n",
      "39/39 [==============================] - 32s 804ms/step - loss: 1.0771 - accuracy: 0.3957 - val_loss: 1.0437 - val_accuracy: 0.4508\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 28s 713ms/step - loss: 1.0076 - accuracy: 0.4729 - val_loss: 1.0378 - val_accuracy: 0.4262\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 28s 714ms/step - loss: 0.9338 - accuracy: 0.5599 - val_loss: 1.1184 - val_accuracy: 0.3743\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 29s 740ms/step - loss: 0.8330 - accuracy: 0.6149 - val_loss: 1.0864 - val_accuracy: 0.4481\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 28s 712ms/step - loss: 0.7148 - accuracy: 0.6847 - val_loss: 1.1324 - val_accuracy: 0.4672\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 28s 708ms/step - loss: 0.6704 - accuracy: 0.6929 - val_loss: 1.4533 - val_accuracy: 0.4044\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 28s 707ms/step - loss: 0.5783 - accuracy: 0.7512 - val_loss: 1.3204 - val_accuracy: 0.4208\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 28s 708ms/step - loss: 0.4592 - accuracy: 0.8186 - val_loss: 1.5653 - val_accuracy: 0.3934\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 28s 708ms/step - loss: 0.4145 - accuracy: 0.8284 - val_loss: 1.6959 - val_accuracy: 0.4235\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - 28s 714ms/step - loss: 0.3829 - accuracy: 0.8358 - val_loss: 1.5136 - val_accuracy: 0.4262\n",
      "12/12 [==============================] - 3s 230ms/step\n",
      "masc: 0.4470173142618398\n",
      "separado: 0.47716197693921775\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 27s 823ms/step - loss: 0.6417 - accuracy: 0.6458 - val_loss: 0.7163 - val_accuracy: 0.5128\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 25s 780ms/step - loss: 0.5431 - accuracy: 0.7330 - val_loss: 0.5311 - val_accuracy: 0.7436\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 23s 711ms/step - loss: 0.4895 - accuracy: 0.7660 - val_loss: 0.5458 - val_accuracy: 0.7120\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 22s 705ms/step - loss: 0.4467 - accuracy: 0.7995 - val_loss: 0.5802 - val_accuracy: 0.7278\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 23s 704ms/step - loss: 0.4112 - accuracy: 0.8118 - val_loss: 0.5602 - val_accuracy: 0.7258\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 23s 708ms/step - loss: 0.3748 - accuracy: 0.8271 - val_loss: 0.5863 - val_accuracy: 0.7258\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 22s 703ms/step - loss: 0.3744 - accuracy: 0.8296 - val_loss: 0.5485 - val_accuracy: 0.7357\n",
      "16/16 [==============================] - 1s 83ms/step\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 13s 168ms/step - loss: 1.0802 - accuracy: 0.3867 - val_loss: 1.0648 - val_accuracy: 0.4083\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 11s 167ms/step - loss: 1.0379 - accuracy: 0.4429 - val_loss: 1.1263 - val_accuracy: 0.3708\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 11s 170ms/step - loss: 0.9807 - accuracy: 0.5074 - val_loss: 1.0567 - val_accuracy: 0.4181\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 11s 168ms/step - loss: 0.9282 - accuracy: 0.5586 - val_loss: 1.0858 - val_accuracy: 0.4398\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 10s 160ms/step - loss: 0.8842 - accuracy: 0.5739 - val_loss: 1.0980 - val_accuracy: 0.4339\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 10s 162ms/step - loss: 0.8471 - accuracy: 0.5946 - val_loss: 1.0798 - val_accuracy: 0.4438\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 10s 160ms/step - loss: 0.7830 - accuracy: 0.6384 - val_loss: 1.1321 - val_accuracy: 0.4517\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 10s 161ms/step - loss: 0.7273 - accuracy: 0.6768 - val_loss: 1.2201 - val_accuracy: 0.4596\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 10s 159ms/step - loss: 0.6748 - accuracy: 0.6961 - val_loss: 1.2908 - val_accuracy: 0.4339\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 10s 159ms/step - loss: 0.6187 - accuracy: 0.7266 - val_loss: 1.3463 - val_accuracy: 0.4497\n",
      "16/16 [==============================] - 1s 33ms/step\n",
      "juntos: 0.4242877179794602\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 6s 219ms/step - loss: 1.0861 - accuracy: 0.4224 - val_loss: 1.0489 - val_accuracy: 0.5397\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 5s 211ms/step - loss: 1.0118 - accuracy: 0.5049 - val_loss: 0.9512 - val_accuracy: 0.4841\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 6s 213ms/step - loss: 0.9361 - accuracy: 0.5456 - val_loss: 0.9456 - val_accuracy: 0.5397\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 6s 212ms/step - loss: 0.8648 - accuracy: 0.5973 - val_loss: 0.9431 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 6s 212ms/step - loss: 0.8024 - accuracy: 0.6318 - val_loss: 1.0424 - val_accuracy: 0.4921\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 6s 218ms/step - loss: 0.7424 - accuracy: 0.6749 - val_loss: 0.9474 - val_accuracy: 0.5714\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 5s 210ms/step - loss: 0.6820 - accuracy: 0.6921 - val_loss: 0.9714 - val_accuracy: 0.5556\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 6s 213ms/step - loss: 0.6694 - accuracy: 0.7044 - val_loss: 1.0996 - val_accuracy: 0.5159\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 5s 211ms/step - loss: 0.5761 - accuracy: 0.7660 - val_loss: 1.7654 - val_accuracy: 0.3254\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 5s 211ms/step - loss: 0.5462 - accuracy: 0.7796 - val_loss: 1.3375 - val_accuracy: 0.5079\n",
      "4/4 [==============================] - 0s 41ms/step\n",
      "fem: 0.46492089470812875\n",
      "Epoch 1/10\n",
      "39/39 [==============================] - 29s 747ms/step - loss: 1.0784 - accuracy: 0.3966 - val_loss: 1.0501 - val_accuracy: 0.4252\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 28s 719ms/step - loss: 1.0027 - accuracy: 0.4795 - val_loss: 1.0469 - val_accuracy: 0.4226\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 28s 728ms/step - loss: 0.9244 - accuracy: 0.5550 - val_loss: 1.1056 - val_accuracy: 0.3806\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 28s 710ms/step - loss: 0.8203 - accuracy: 0.6199 - val_loss: 1.1259 - val_accuracy: 0.4331\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 28s 715ms/step - loss: 0.6970 - accuracy: 0.7077 - val_loss: 1.2037 - val_accuracy: 0.4488\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 28s 719ms/step - loss: 0.6557 - accuracy: 0.7192 - val_loss: 1.4491 - val_accuracy: 0.4199\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 28s 724ms/step - loss: 0.5521 - accuracy: 0.7685 - val_loss: 1.4597 - val_accuracy: 0.4199\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 28s 713ms/step - loss: 0.4435 - accuracy: 0.8177 - val_loss: 1.5524 - val_accuracy: 0.4016\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 28s 721ms/step - loss: 0.3867 - accuracy: 0.8407 - val_loss: 1.6982 - val_accuracy: 0.3990\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - 28s 715ms/step - loss: 0.3611 - accuracy: 0.8539 - val_loss: 1.5798 - val_accuracy: 0.4304\n",
      "12/12 [==============================] - 2s 161ms/step\n",
      "masc: 0.40944387284096767\n",
      "separado: 0.4228010226713556\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 31s 945ms/step - loss: 0.6401 - accuracy: 0.6438 - val_loss: 0.8186 - val_accuracy: 0.4201\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 29s 895ms/step - loss: 0.5383 - accuracy: 0.7369 - val_loss: 0.5260 - val_accuracy: 0.7475\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 28s 884ms/step - loss: 0.4841 - accuracy: 0.7754 - val_loss: 0.5486 - val_accuracy: 0.7140\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 28s 882ms/step - loss: 0.4445 - accuracy: 0.7990 - val_loss: 0.5869 - val_accuracy: 0.7278\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 30s 928ms/step - loss: 0.4080 - accuracy: 0.8118 - val_loss: 0.5400 - val_accuracy: 0.7416\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.3828 - accuracy: 0.8172 - val_loss: 0.6724 - val_accuracy: 0.7179\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.3761 - accuracy: 0.8261 - val_loss: 0.5507 - val_accuracy: 0.7219\n",
      "16/16 [==============================] - 4s 240ms/step\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 15s 222ms/step - loss: 1.0809 - accuracy: 0.3946 - val_loss: 1.0642 - val_accuracy: 0.4122\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 14s 220ms/step - loss: 1.0385 - accuracy: 0.4488 - val_loss: 1.1220 - val_accuracy: 0.3945\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 14s 223ms/step - loss: 0.9811 - accuracy: 0.5138 - val_loss: 1.0668 - val_accuracy: 0.4122\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 14s 219ms/step - loss: 0.9235 - accuracy: 0.5547 - val_loss: 1.0938 - val_accuracy: 0.4300\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 14s 219ms/step - loss: 0.8823 - accuracy: 0.5773 - val_loss: 1.1205 - val_accuracy: 0.4320\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 14s 218ms/step - loss: 0.8409 - accuracy: 0.5995 - val_loss: 1.0933 - val_accuracy: 0.4320\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 14s 219ms/step - loss: 0.7877 - accuracy: 0.6345 - val_loss: 1.1258 - val_accuracy: 0.4438\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 14s 219ms/step - loss: 0.7236 - accuracy: 0.6828 - val_loss: 1.2619 - val_accuracy: 0.4596\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 14s 217ms/step - loss: 0.6756 - accuracy: 0.6897 - val_loss: 1.2960 - val_accuracy: 0.4221\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 14s 220ms/step - loss: 0.6275 - accuracy: 0.7296 - val_loss: 1.3239 - val_accuracy: 0.4576\n",
      "16/16 [==============================] - 1s 66ms/step\n",
      "juntos: 0.43066815239130846\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 8s 280ms/step - loss: 1.0885 - accuracy: 0.4200 - val_loss: 1.0706 - val_accuracy: 0.5308\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 7s 271ms/step - loss: 1.0327 - accuracy: 0.4828 - val_loss: 0.9925 - val_accuracy: 0.4846\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 7s 270ms/step - loss: 0.9635 - accuracy: 0.5333 - val_loss: 0.9894 - val_accuracy: 0.4923\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 7s 272ms/step - loss: 0.9005 - accuracy: 0.5764 - val_loss: 1.0202 - val_accuracy: 0.4769\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 7s 270ms/step - loss: 0.8346 - accuracy: 0.6047 - val_loss: 1.0941 - val_accuracy: 0.4462\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 7s 273ms/step - loss: 0.7656 - accuracy: 0.6466 - val_loss: 1.0447 - val_accuracy: 0.5462\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 7s 272ms/step - loss: 0.7274 - accuracy: 0.6736 - val_loss: 1.0726 - val_accuracy: 0.4923\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 7s 271ms/step - loss: 0.6849 - accuracy: 0.6872 - val_loss: 1.1763 - val_accuracy: 0.4846\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 7s 272ms/step - loss: 0.6010 - accuracy: 0.7525 - val_loss: 1.4531 - val_accuracy: 0.4615\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 7s 272ms/step - loss: 0.5734 - accuracy: 0.7635 - val_loss: 1.3627 - val_accuracy: 0.5000\n",
      "5/5 [==============================] - 0s 66ms/step\n",
      "fem: 0.4778010148792981\n",
      "Epoch 1/10\n",
      "39/39 [==============================] - 34s 866ms/step - loss: 1.0741 - accuracy: 0.3974 - val_loss: 1.0472 - val_accuracy: 0.4271\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 32s 833ms/step - loss: 1.0111 - accuracy: 0.4696 - val_loss: 1.0422 - val_accuracy: 0.4164\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 33s 842ms/step - loss: 0.9362 - accuracy: 0.5402 - val_loss: 1.1521 - val_accuracy: 0.3528\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 32s 834ms/step - loss: 0.8302 - accuracy: 0.6273 - val_loss: 1.0942 - val_accuracy: 0.4403\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 32s 820ms/step - loss: 0.7138 - accuracy: 0.6897 - val_loss: 1.2500 - val_accuracy: 0.4324\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 34s 882ms/step - loss: 0.6970 - accuracy: 0.6856 - val_loss: 1.4324 - val_accuracy: 0.4111\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 33s 835ms/step - loss: 0.5835 - accuracy: 0.7545 - val_loss: 1.3501 - val_accuracy: 0.4191\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 32s 824ms/step - loss: 0.4633 - accuracy: 0.8021 - val_loss: 1.7650 - val_accuracy: 0.4005\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 32s 827ms/step - loss: 0.4220 - accuracy: 0.8268 - val_loss: 1.7238 - val_accuracy: 0.4085\n",
      "12/12 [==============================] - 3s 237ms/step\n",
      "masc: 0.41696598039701566\n",
      "separado: 0.44062709563619135\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.6296 - accuracy: 0.6562 - val_loss: 0.6885 - val_accuracy: 0.5483\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.5355 - accuracy: 0.7345 - val_loss: 0.5260 - val_accuracy: 0.7495\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.4846 - accuracy: 0.7704 - val_loss: 0.5407 - val_accuracy: 0.7160\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.4420 - accuracy: 0.8005 - val_loss: 0.5899 - val_accuracy: 0.7278\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 42s 1s/step - loss: 0.4023 - accuracy: 0.8187 - val_loss: 0.5439 - val_accuracy: 0.7357\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 41s 1s/step - loss: 0.3800 - accuracy: 0.8197 - val_loss: 0.6736 - val_accuracy: 0.7179\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 36s 1s/step - loss: 0.3652 - accuracy: 0.8315 - val_loss: 0.5618 - val_accuracy: 0.7239\n",
      "16/16 [==============================] - 4s 244ms/step\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 15s 227ms/step - loss: 1.0784 - accuracy: 0.3990 - val_loss: 1.0603 - val_accuracy: 0.4024\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 14s 224ms/step - loss: 1.0329 - accuracy: 0.4571 - val_loss: 1.1301 - val_accuracy: 0.3886\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 14s 222ms/step - loss: 0.9758 - accuracy: 0.5172 - val_loss: 1.0743 - val_accuracy: 0.4162\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 14s 221ms/step - loss: 0.9210 - accuracy: 0.5552 - val_loss: 1.1055 - val_accuracy: 0.4379\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 14s 220ms/step - loss: 0.8878 - accuracy: 0.5640 - val_loss: 1.0894 - val_accuracy: 0.4320\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 14s 219ms/step - loss: 0.8377 - accuracy: 0.6000 - val_loss: 1.0904 - val_accuracy: 0.4359\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 14s 219ms/step - loss: 0.7851 - accuracy: 0.6419 - val_loss: 1.1308 - val_accuracy: 0.4458\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 14s 224ms/step - loss: 0.7172 - accuracy: 0.6808 - val_loss: 1.2398 - val_accuracy: 0.4517\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 14s 220ms/step - loss: 0.6758 - accuracy: 0.7059 - val_loss: 1.2999 - val_accuracy: 0.4162\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 14s 216ms/step - loss: 0.6183 - accuracy: 0.7286 - val_loss: 1.3007 - val_accuracy: 0.4458\n",
      "16/16 [==============================] - 1s 66ms/step\n",
      "juntos: 0.4326083297778722\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 9s 317ms/step - loss: 1.0886 - accuracy: 0.4101 - val_loss: 1.0619 - val_accuracy: 0.5447\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 8s 308ms/step - loss: 1.0247 - accuracy: 0.4877 - val_loss: 0.9701 - val_accuracy: 0.4959\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 8s 303ms/step - loss: 0.9517 - accuracy: 0.5369 - val_loss: 0.9758 - val_accuracy: 0.5041\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 8s 298ms/step - loss: 0.8833 - accuracy: 0.5751 - val_loss: 0.9433 - val_accuracy: 0.5366\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 8s 296ms/step - loss: 0.8094 - accuracy: 0.6207 - val_loss: 0.9902 - val_accuracy: 0.5285\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 8s 295ms/step - loss: 0.7518 - accuracy: 0.6367 - val_loss: 1.0118 - val_accuracy: 0.5935\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 8s 298ms/step - loss: 0.6914 - accuracy: 0.6983 - val_loss: 1.0341 - val_accuracy: 0.5528\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 8s 298ms/step - loss: 0.6636 - accuracy: 0.7118 - val_loss: 1.1258 - val_accuracy: 0.5203\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 8s 301ms/step - loss: 0.5938 - accuracy: 0.7525 - val_loss: 1.4211 - val_accuracy: 0.4797\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 8s 302ms/step - loss: 0.5313 - accuracy: 0.7759 - val_loss: 1.2682 - val_accuracy: 0.5366\n",
      "4/4 [==============================] - 3s 108ms/step\n",
      "fem: 0.5184263038548753\n",
      "Epoch 1/10\n",
      "39/39 [==============================] - 35s 890ms/step - loss: 1.0784 - accuracy: 0.3875 - val_loss: 1.0488 - val_accuracy: 0.4427\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 33s 860ms/step - loss: 1.0120 - accuracy: 0.4598 - val_loss: 1.0385 - val_accuracy: 0.4297\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 32s 835ms/step - loss: 0.9328 - accuracy: 0.5608 - val_loss: 1.1758 - val_accuracy: 0.3464\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 33s 836ms/step - loss: 0.8323 - accuracy: 0.6264 - val_loss: 1.1036 - val_accuracy: 0.4323\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 33s 847ms/step - loss: 0.7159 - accuracy: 0.6929 - val_loss: 1.1256 - val_accuracy: 0.4661\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 34s 872ms/step - loss: 0.6626 - accuracy: 0.7077 - val_loss: 1.5433 - val_accuracy: 0.4219\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 33s 857ms/step - loss: 0.5819 - accuracy: 0.7512 - val_loss: 1.3374 - val_accuracy: 0.4297\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 33s 846ms/step - loss: 0.4568 - accuracy: 0.8062 - val_loss: 1.5580 - val_accuracy: 0.3958\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 33s 836ms/step - loss: 0.4075 - accuracy: 0.8325 - val_loss: 1.7875 - val_accuracy: 0.4323\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - 33s 838ms/step - loss: 0.3845 - accuracy: 0.8342 - val_loss: 1.5735 - val_accuracy: 0.4323\n",
      "12/12 [==============================] - 3s 236ms/step\n",
      "masc: 0.4532591817980163\n",
      "separado: 0.4702239877709784\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RESULTADOS FINAIS\n",
      "flat: 0.43059479931921735\n",
      "local fem: 0.5017280782992167\n",
      "local masc: 0.41964735344388215\n",
      "hierq: 0.45191055838476035\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "VETORES\n",
      "flat: [0.4147901838067996, 0.4208521789020385, 0.4368178510793112, 0.42625455074996355, 0.45351835577399485, 0.43239552378124246, 0.43375514895018324, 0.4242877179794602, 0.43066815239130846, 0.4326083297778722]\n",
      "local fem: [0.5140594699418229, 0.5644910071010211, 0.5787811318800808, 0.4266193853427896, 0.46072092159048683, 0.4817460317460318, 0.5297146219476316, 0.46492089470812875, 0.4778010148792981, 0.5184263038548753]\n",
      "local masc: [0.430296951501362, 0.4391006251260335, 0.42962152521566094, 0.40793763288447904, 0.42559382613556346, 0.33723662427788254, 0.4470173142618398, 0.40944387284096767, 0.41696598039701566, 0.4532591817980163]\n",
      "hierq: [0.45787283122953587, 0.46828827080366825, 0.4784829746178074, 0.43144703315736005, 0.4483401126377203, 0.4238602783837684, 0.47716197693921775, 0.4228010226713556, 0.44062709563619135, 0.4702239877709784]\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(r\"C:\\Users\\alici\\Documents\\tcc\\github2\\tcc-v2\\blogset-br\\particoes\\houdout\\train.csv\")\n",
    "df_test = pd.read_csv(r\"C:\\Users\\alici\\Documents\\tcc\\github2\\tcc-v2\\blogset-br\\particoes\\houdout\\test.csv\")\n",
    "\n",
    "f = []\n",
    "l_fem = []\n",
    "l_masc = []\n",
    "h_total = []\n",
    "for _ in range(10):\n",
    "    X_train = df_train[\"Texts\"].apply(clean_text).to_numpy()\n",
    "    X_test = df_test[\"Texts\"].apply(clean_text).to_numpy()\n",
    "    y_train_gender = df_train[\"GenderClass\"].to_numpy()\n",
    "    y_test_gender = df_test[\"GenderClass\"].to_numpy()\n",
    "\n",
    "    num_words = []\n",
    "    for text in (X_train.tolist()+X_test.tolist()):\n",
    "        num_words.append(len(text.split()))\n",
    "\n",
    "    mean = sum(num_words)//len(num_words)\n",
    "\n",
    "    train_texts = X_train.tolist()\n",
    "    test_texts = X_test.tolist()\n",
    "\n",
    "    tfidfvec = TfidfVectorizer(max_features = mean, max_df=0.9)\n",
    "    tfidfvec.fit(train_texts)\n",
    "    tfidf_train = tfidfvec.transform(train_texts).toarray()\n",
    "    tfidf_test = tfidfvec.transform(test_texts).toarray()\n",
    "\n",
    "    X_train = tfidf_train.reshape(tfidf_train.shape[0],tfidf_train.shape[1],1)\n",
    "    X_test = tfidf_test.reshape(tfidf_test.shape[0],tfidf_test.shape[1],1)\n",
    "\n",
    "    y_train_gander_cat = keras.utils.to_categorical(y_train_gender,num_classes=2)\n",
    "    y_test_gender_cat = keras.utils.to_categorical(y_test_gender,num_classes=2)\n",
    "\n",
    "    size = X_test.shape[1]\n",
    "\n",
    "    model_gender = create_model_gender(param[\"gender\"][\"params\"][\"filters\"], \n",
    "                                        kernel_size=param[\"gender\"][\"params\"][\"kernel_size\"], \n",
    "                                        strides=param[\"gender\"][\"params\"][\"strides\"], \n",
    "                                        dropout_rate=param[\"gender\"][\"params\"][\"dropout_rate\"], \n",
    "                                        pool_size=param[\"gender\"][\"params\"][\"pool_size\"], \n",
    "                                        dense_units=512, \n",
    "                                        max_len=size)\n",
    "\n",
    "    callback = [\n",
    "        EarlyStopping(patience=5, monitor='val_accuracy', mode='max', restore_best_weights=True),\n",
    "    ]\n",
    "    model_gender.fit(X_train, y_train_gander_cat,\n",
    "                    validation_data=(X_test,y_test_gender_cat), \n",
    "                    batch_size=param[\"gender\"][\"params\"][\"batch_size\"],\n",
    "                    epochs=param[\"gender\"][\"params\"][\"epochs\"],\n",
    "                    callbacks=callback)\n",
    "\n",
    "    y_pred_gender = model_gender.predict(\n",
    "        X_test\n",
    "    )\n",
    "\n",
    "    y_pred_list_gender = [np.argmax(x, axis=-1) for x in y_pred_gender]\n",
    "\n",
    "    df_test[\"PredictGender\"] = y_pred_list_gender\n",
    "\n",
    "    y_train_age = df_train[\"AgeClass\"].to_numpy()\n",
    "    y_test_age = df_test[\"AgeClass\"].to_numpy()\n",
    "\n",
    "    y_train_age = keras.utils.to_categorical(y_train_age,num_classes=3)\n",
    "    y_test_age_cat = keras.utils.to_categorical(y_test_age,num_classes=3)\n",
    "\n",
    "    model_age = create_model_age(param[\"age\"][\"params\"][\"filters\"], \n",
    "                                        kernel_size=param[\"age\"][\"params\"][\"kernel_size\"], \n",
    "                                        strides=param[\"age\"][\"params\"][\"strides\"], \n",
    "                                        dropout_rate=param[\"age\"][\"params\"][\"dropout_rate\"], \n",
    "                                        pool_size=param[\"age\"][\"params\"][\"pool_size\"], \n",
    "                                        dense_units=512, \n",
    "                                        max_len=size)\n",
    "\n",
    "    model_age.fit(X_train,y_train_age,validation_data=(X_test,y_test_age_cat), \n",
    "                    batch_size=param[\"age\"][\"params\"][\"batch_size\"],\n",
    "                    epochs=param[\"age\"][\"params\"][\"epochs\"],\n",
    "                    callbacks=callback)\n",
    "\n",
    "    y_pred_age = model_age.predict(\n",
    "        X_test\n",
    "    )\n",
    "\n",
    "    y_pred_list_age = [np.argmax(x, axis=-1) for x in y_pred_age]\n",
    "\n",
    "    print(\"juntos: \", end=\"\")\n",
    "    print(metrics.f1_score(y_test_age, y_pred_list_age, average='macro'))\n",
    "    f.append(metrics.f1_score(y_test_age, y_pred_list_age, average='macro'))\n",
    "\n",
    "    df_train_fem = df_train[df_train[\"GenderClass\"]==1]\n",
    "    df_test_fem = df_test[df_test[\"PredictGender\"]==1]\n",
    "\n",
    "    X_train_fem = df_train_fem[\"Texts\"].apply(clean_text).to_numpy()\n",
    "    X_test_fem = df_test_fem[\"Texts\"].apply(clean_text).to_numpy()\n",
    "    y_train_fem = df_train_fem[\"AgeClass\"].to_numpy()\n",
    "    y_test_fem = df_test_fem[\"AgeClass\"].to_numpy()\n",
    "\n",
    "    num_words_fem = []\n",
    "    for text in (X_train_fem.tolist()+X_test_fem.tolist()):\n",
    "        num_words_fem.append(len(text.split()))\n",
    "\n",
    "    mean_fem = sum(num_words_fem)//len(num_words_fem)\n",
    "\n",
    "    train_texts_fem = X_train_fem.tolist()\n",
    "    test_texts_fem = X_test_fem.tolist()\n",
    "\n",
    "    tfidfvec_fem = TfidfVectorizer(max_features = mean_fem, max_df=0.9)\n",
    "    tfidfvec_fem.fit(train_texts_fem)\n",
    "    tfidf_train_fem = tfidfvec_fem.transform(train_texts_fem).toarray()\n",
    "    tfidf_test_fem = tfidfvec_fem.transform(test_texts_fem).toarray()\n",
    "\n",
    "    X_train_fem = tfidf_train_fem.reshape(tfidf_train_fem.shape[0],tfidf_train_fem.shape[1],1)\n",
    "    X_test_fem = tfidf_test_fem.reshape(tfidf_test_fem.shape[0],tfidf_test_fem.shape[1],1)\n",
    "\n",
    "    y_train_fem = keras.utils.to_categorical(y_train_fem,num_classes=3)\n",
    "    y_test_fem_cat = keras.utils.to_categorical(y_test_fem,num_classes=3)\n",
    "\n",
    "    size_fem = X_test_fem.shape[1]\n",
    "\n",
    "    model_fem = create_model_age(param[\"age/fem\"][\"params\"][\"filters\"], \n",
    "                                        kernel_size=param[\"age/fem\"][\"params\"][\"kernel_size\"], \n",
    "                                        strides=param[\"age/fem\"][\"params\"][\"strides\"], \n",
    "                                        dropout_rate=param[\"age/fem\"][\"params\"][\"dropout_rate\"], \n",
    "                                        pool_size=param[\"age/fem\"][\"params\"][\"pool_size\"], \n",
    "                                        dense_units=512, \n",
    "                                        max_len=size_fem)\n",
    "\n",
    "\n",
    "    model_fem.fit(X_train_fem,y_train_fem,validation_data=(X_test_fem, y_test_fem_cat), \n",
    "                    batch_size=param[\"age/fem\"][\"params\"][\"batch_size\"],\n",
    "                    epochs=param[\"age/fem\"][\"params\"][\"epochs\"],\n",
    "                    callbacks=callback)\n",
    "\n",
    "    y_pred_fem = model_fem.predict(\n",
    "        X_test_fem\n",
    "    )\n",
    "\n",
    "    y_pred_list_fem = [np.argmax(x, axis=-1) for x in y_pred_fem]\n",
    "    print(\"fem: \", end=\"\")\n",
    "    print(metrics.f1_score(y_test_fem, y_pred_list_fem, average='macro'))\n",
    "    l_fem.append(metrics.f1_score(y_test_fem, y_pred_list_fem, average='macro'))\n",
    "\n",
    "\n",
    "    df_train_masc = df_train[df_train[\"GenderClass\"]==0]\n",
    "    df_test_masc = df_test[df_test[\"PredictGender\"]==0]\n",
    "\n",
    "    X_train_masc = df_train_masc[\"Texts\"].apply(clean_text).to_numpy()\n",
    "    X_test_masc = df_test_masc[\"Texts\"].apply(clean_text).to_numpy()\n",
    "    y_train_masc = df_train_masc[\"AgeClass\"].to_numpy()\n",
    "    y_test_masc = df_test_masc[\"AgeClass\"].to_numpy()\n",
    "\n",
    "    num_words_masc = []\n",
    "    for text in (X_train_masc.tolist()+X_test_masc.tolist()):\n",
    "        num_words_masc.append(len(text.split()))\n",
    "\n",
    "    mean_masc = sum(num_words_masc)//len(num_words_masc)\n",
    "\n",
    "    train_texts_masc = X_train_masc.tolist()\n",
    "    test_texts_masc = X_test_masc.tolist()\n",
    "\n",
    "    tfidfvec_masc = TfidfVectorizer(max_features = mean_masc, max_df=0.9)\n",
    "    tfidfvec_masc.fit(train_texts_masc)\n",
    "    tfidf_train_masc = tfidfvec_masc.transform(train_texts_masc).toarray()\n",
    "    tfidf_test_masc = tfidfvec_masc.transform(test_texts_masc).toarray()\n",
    "\n",
    "    X_train_masc = tfidf_train_masc.reshape(tfidf_train_masc.shape[0],tfidf_train_masc.shape[1],1)\n",
    "    X_test_masc = tfidf_test_masc.reshape(tfidf_test_masc.shape[0],tfidf_test_masc.shape[1],1)\n",
    "\n",
    "    y_train_masc = keras.utils.to_categorical(y_train_masc,num_classes=3)\n",
    "    y_test_masc_cat = keras.utils.to_categorical(y_test_masc,num_classes=3)\n",
    "\n",
    "    size_masc = X_test_masc.shape[1]\n",
    "\n",
    "    model_masc = create_model_age(param[\"age/masc\"][\"params\"][\"filters\"], \n",
    "                                        kernel_size=param[\"age/masc\"][\"params\"][\"kernel_size\"], \n",
    "                                        strides=param[\"age/masc\"][\"params\"][\"strides\"], \n",
    "                                        dropout_rate=param[\"age/masc\"][\"params\"][\"dropout_rate\"], \n",
    "                                        pool_size=param[\"age/masc\"][\"params\"][\"pool_size\"], \n",
    "                                        dense_units=512, \n",
    "                                        max_len=size_masc)\n",
    "\n",
    "    callback = [\n",
    "        EarlyStopping(patience=5, monitor='val_accuracy', mode='max', restore_best_weights=True),\n",
    "    ]\n",
    "\n",
    "    model_masc.fit(X_train_masc,y_train_masc,validation_data=(X_test_masc,y_test_masc_cat), \n",
    "                    batch_size=param[\"age/masc\"][\"params\"][\"batch_size\"],\n",
    "                    epochs=param[\"age/masc\"][\"params\"][\"epochs\"],\n",
    "                    callbacks=callback)\n",
    "\n",
    "    y_pred_masc = model_masc.predict(\n",
    "        X_test_masc\n",
    "    )\n",
    "\n",
    "    y_pred_list_masc = [np.argmax(x, axis=-1) for x in y_pred_masc]\n",
    "\n",
    "    print(\"masc: \", end=\"\")\n",
    "    print(metrics.f1_score(y_test_masc, y_pred_list_masc, average='macro'))\n",
    "    l_masc.append(metrics.f1_score(y_test_masc, y_pred_list_masc, average='macro'))\n",
    "\n",
    "    y_test_sep = y_test_fem.tolist() + y_test_masc.tolist()\n",
    "    y_pred_list_sep = y_pred_list_fem + y_pred_list_masc\n",
    "    print(\"separado: \", end=\"\")\n",
    "    print(metrics.f1_score(y_test_sep, y_pred_list_sep, average='macro'))\n",
    "    h_total.append(metrics.f1_score(y_test_sep, y_pred_list_sep, average='macro'))\n",
    "\n",
    "print(\"\\n\\n\\n\\n\\n\\nRESULTADOS FINAIS\")\n",
    "print(\"flat: \", end=\"\")\n",
    "print(sum(f)/len(f))\n",
    "print(\"local fem: \", end=\"\")\n",
    "print(sum(l_fem)/len(l_fem))\n",
    "print(\"local masc: \", end=\"\")\n",
    "print(sum(l_masc)/len(l_masc))\n",
    "print(\"hierq: \", end=\"\")\n",
    "print(sum(h_total)/len(h_total))\n",
    "\n",
    "print(\"\\n\\n\\n\\n\\n\\nVETORES\")\n",
    "print(\"flat: \", end=\"\")\n",
    "print(f)\n",
    "print(\"local fem: \", end=\"\")\n",
    "print(l_fem)\n",
    "print(\"local masc: \", end=\"\")\n",
    "print(l_masc)\n",
    "print(\"hierq: \", end=\"\")\n",
    "print(h_total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac26e9ee9434047e2b6179ca7c094dd6d7a5c4307efa62cbdc343ee78cec5e23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

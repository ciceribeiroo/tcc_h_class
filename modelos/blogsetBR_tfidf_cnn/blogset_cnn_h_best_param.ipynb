{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import tensorflow \n",
    "tensorflow.random.set_seed(1) \n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alici\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D, Convolution1D\n",
    "from keras.optimizers import Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    all_words = text.split(\" \")\n",
    "    clean_text = [i for i in all_words if i not in stopwords and i!=\"\"]\n",
    "    return \" \".join(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    import re\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_texts(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    clean_text = remove_stopwords(text)\n",
    "    clean_text = remove_html_tags(clean_text)\n",
    "    clean_text = lower_texts(clean_text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_gender(filters = [100], kernel_size = [50], strides = [100], \n",
    "                 dropout_rate = 0.5, pool_size = [5], dense_units = 100, max_len = 1000):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # conv 1\n",
    "    model.add(Conv1D(filters = filters[0], \n",
    "                     kernel_size = kernel_size[0],\n",
    "                     strides = strides[0], \n",
    "                     activation = 'relu', \n",
    "                     input_shape = (max_len, 1) ))\n",
    "\n",
    "    # pooling layer 1\n",
    "    for i in range(len(pool_size)):\n",
    "        model.add(MaxPooling1D(pool_size = pool_size[i], strides = 1))\n",
    "        model.add(Activation('relu'))\n",
    "    \n",
    "    #model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    if dropout_rate is not None:\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        \n",
    "    model.add(Dense(units = dense_units, activation = 'relu'))\n",
    "    model.add(Dense(units = 2, activation = 'softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer = Adadelta(\n",
    "       learning_rate=1, name=\"Adadelta\"\n",
    "    ), metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_age(filters = [100], kernel_size = [50], strides = [100], \n",
    "                 dropout_rate = 0.5, pool_size = [5], dense_units = 100, max_len = 1000):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # conv 1\n",
    "    model.add(Conv1D(filters = filters[0], \n",
    "                     kernel_size = kernel_size[0],\n",
    "                     strides = strides[0], \n",
    "                     activation = 'relu', \n",
    "                     input_shape = (max_len, 1) ))\n",
    "\n",
    "    # pooling layer 1\n",
    "    for i in range(len(pool_size)):\n",
    "        model.add(MaxPooling1D(pool_size = pool_size[i], strides = 1))\n",
    "        model.add(Activation('relu'))\n",
    "    \n",
    "    #model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    if dropout_rate is not None:\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        \n",
    "    model.add(Dense(units = dense_units, activation = 'relu'))\n",
    "    model.add(Dense(units = 3, activation = 'softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer = Adadelta(\n",
    "       learning_rate=1, name=\"Adadelta\"\n",
    "    ), metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 85s 1s/step - loss: 0.6461 - accuracy: 0.6571 - val_loss: 0.5791 - val_accuracy: 0.7278\n",
      "16/16 [==============================] - 4s 227ms/step\n",
      "64/64 [==============================] - 72s 1s/step - loss: 1.0722 - accuracy: 0.3966 - val_loss: 1.0345 - val_accuracy: 0.4497\n",
      "16/16 [==============================] - 3s 186ms/step\n",
      "juntos: 0.4337421742227465\n",
      "26/26 [==============================] - 22s 831ms/step - loss: 1.0914 - accuracy: 0.3929 - val_loss: 1.0693 - val_accuracy: 0.4400\n",
      "7/7 [==============================] - 1s 171ms/step\n",
      "fem: 0.3980842911877394\n",
      "39/39 [==============================] - 48s 1s/step - loss: 1.0905 - accuracy: 0.3834 - val_loss: 1.0560 - val_accuracy: 0.4137\n",
      "10/10 [==============================] - 2s 185ms/step\n",
      "masc: 0.3063554802685237\n",
      "separado: 0.40223775987569876\n",
      "64/64 [==============================] - 63s 963ms/step - loss: 0.6469 - accuracy: 0.6350 - val_loss: 0.5825 - val_accuracy: 0.7278\n",
      "16/16 [==============================] - 3s 163ms/step\n",
      "64/64 [==============================] - 64s 985ms/step - loss: 1.0727 - accuracy: 0.3995 - val_loss: 1.0405 - val_accuracy: 0.4320\n",
      "16/16 [==============================] - 3s 172ms/step\n",
      "juntos: 0.40730170532075355\n",
      "26/26 [==============================] - 37s 1s/step - loss: 1.0982 - accuracy: 0.3941 - val_loss: 1.0725 - val_accuracy: 0.4271\n",
      "6/6 [==============================] - 2s 387ms/step\n",
      "fem: 0.37423946483625664\n",
      "39/39 [==============================] - 80s 2s/step - loss: 1.0858 - accuracy: 0.3875 - val_loss: 1.0522 - val_accuracy: 0.4571\n",
      "10/10 [==============================] - 6s 585ms/step\n",
      "masc: 0.34371643394199786\n",
      "separado: 0.4257702079938321\n",
      "64/64 [==============================] - 85s 1s/step - loss: 0.6474 - accuracy: 0.6360 - val_loss: 0.5815 - val_accuracy: 0.7318\n",
      "16/16 [==============================] - 6s 379ms/step\n",
      "64/64 [==============================] - 84s 1s/step - loss: 1.0717 - accuracy: 0.3980 - val_loss: 1.0337 - val_accuracy: 0.4497\n",
      "16/16 [==============================] - 6s 382ms/step\n",
      "juntos: 0.42873082520284944\n",
      "26/26 [==============================] - 19s 707ms/step - loss: 1.1006 - accuracy: 0.3855 - val_loss: 1.0758 - val_accuracy: 0.4118\n",
      "7/7 [==============================] - 1s 128ms/step\n",
      "fem: 0.3412698412698412\n",
      "39/39 [==============================] - 92s 2s/step - loss: 1.0925 - accuracy: 0.3834 - val_loss: 1.0591 - val_accuracy: 0.4389\n",
      "10/10 [==============================] - 7s 739ms/step\n",
      "masc: 0.3289549772821148\n",
      "separado: 0.41055782445295214\n",
      "64/64 [==============================] - 121s 2s/step - loss: 0.6546 - accuracy: 0.6281 - val_loss: 0.5921 - val_accuracy: 0.7061\n",
      "16/16 [==============================] - 12s 743ms/step\n",
      "64/64 [==============================] - 139s 2s/step - loss: 1.0726 - accuracy: 0.4000 - val_loss: 1.0400 - val_accuracy: 0.4339\n",
      "16/16 [==============================] - 8s 476ms/step\n",
      "juntos: 0.40638576195135245\n",
      "26/26 [==============================] - 24s 890ms/step - loss: 1.1012 - accuracy: 0.3978 - val_loss: 1.0818 - val_accuracy: 0.4093\n",
      "7/7 [==============================] - 2s 226ms/step\n",
      "fem: 0.35371318822023046\n",
      "39/39 [==============================] - 57s 1s/step - loss: 1.0801 - accuracy: 0.4089 - val_loss: 1.0451 - val_accuracy: 0.4486\n",
      "10/10 [==============================] - 2s 232ms/step\n",
      "masc: 0.33571393145861234\n",
      "separado: 0.4143108220682059\n",
      "64/64 [==============================] - 135s 2s/step - loss: 0.6589 - accuracy: 0.6399 - val_loss: 0.6006 - val_accuracy: 0.6943\n",
      "16/16 [==============================] - 15s 904ms/step\n",
      "64/64 [==============================] - 129s 2s/step - loss: 1.0714 - accuracy: 0.3926 - val_loss: 1.0323 - val_accuracy: 0.4675\n",
      "16/16 [==============================] - 9s 588ms/step\n",
      "juntos: 0.45169742730209905\n",
      "26/26 [==============================] - 29s 1s/step - loss: 1.0892 - accuracy: 0.3953 - val_loss: 1.0667 - val_accuracy: 0.4615\n",
      "7/7 [==============================] - 3s 359ms/step\n",
      "fem: 0.4342227202519761\n",
      "39/39 [==============================] - 70s 2s/step - loss: 1.0873 - accuracy: 0.3826 - val_loss: 1.0499 - val_accuracy: 0.4580\n",
      "9/9 [==============================] - 4s 430ms/step\n",
      "masc: 0.3506219692177946\n",
      "separado: 0.45028180354267316\n",
      "64/64 [==============================] - 76s 1s/step - loss: 0.6584 - accuracy: 0.6261 - val_loss: 0.5937 - val_accuracy: 0.7120\n",
      "16/16 [==============================] - 5s 328ms/step\n",
      "64/64 [==============================] - 97s 1s/step - loss: 1.0716 - accuracy: 0.4000 - val_loss: 1.0351 - val_accuracy: 0.4517\n",
      "16/16 [==============================] - 5s 329ms/step\n",
      "juntos: 0.43384843369964105\n",
      "26/26 [==============================] - 30s 1s/step - loss: 1.0981 - accuracy: 0.3978 - val_loss: 1.0740 - val_accuracy: 0.4444\n",
      "7/7 [==============================] - 2s 332ms/step\n",
      "fem: 0.3950756558331096\n",
      "39/39 [==============================] - 75s 2s/step - loss: 1.0895 - accuracy: 0.3883 - val_loss: 1.0541 - val_accuracy: 0.4304\n",
      "10/10 [==============================] - 6s 511ms/step\n",
      "masc: 0.313433538641201\n",
      "separado: 0.42923219607127655\n",
      "64/64 [==============================] - 92s 1s/step - loss: 0.6516 - accuracy: 0.6296 - val_loss: 0.5818 - val_accuracy: 0.7318\n",
      "16/16 [==============================] - 8s 506ms/step\n",
      "64/64 [==============================] - 92s 1s/step - loss: 1.0710 - accuracy: 0.3985 - val_loss: 1.0345 - val_accuracy: 0.4458\n",
      "16/16 [==============================] - 7s 413ms/step\n",
      "juntos: 0.42882528385513563\n",
      "26/26 [==============================] - 29s 981ms/step - loss: 1.0922 - accuracy: 0.4076 - val_loss: 1.0700 - val_accuracy: 0.4421\n",
      "6/6 [==============================] - 2s 288ms/step\n",
      "fem: 0.39179621484291943\n",
      "39/39 [==============================] - 93s 2s/step - loss: 1.0932 - accuracy: 0.3810 - val_loss: 1.0565 - val_accuracy: 0.4511\n",
      "10/10 [==============================] - 9s 813ms/step\n",
      "masc: 0.3387790775850477\n",
      "separado: 0.4292905270342742\n",
      "64/64 [==============================] - 115s 2s/step - loss: 0.6408 - accuracy: 0.6571 - val_loss: 0.5726 - val_accuracy: 0.7318\n",
      "16/16 [==============================] - 9s 587ms/step\n",
      "64/64 [==============================] - 105s 2s/step - loss: 1.0702 - accuracy: 0.4015 - val_loss: 1.0335 - val_accuracy: 0.4497\n",
      "16/16 [==============================] - 10s 615ms/step\n",
      "juntos: 0.4300741235396484\n",
      "26/26 [==============================] - 29s 1s/step - loss: 1.0952 - accuracy: 0.3978 - val_loss: 1.0693 - val_accuracy: 0.4369\n",
      "7/7 [==============================] - 2s 276ms/step\n",
      "fem: 0.39075630252100835\n",
      "39/39 [==============================] - 63s 2s/step - loss: 1.0933 - accuracy: 0.3842 - val_loss: 1.0593 - val_accuracy: 0.4485\n",
      "10/10 [==============================] - 5s 452ms/step\n",
      "masc: 0.3369458128078818\n",
      "separado: 0.4287071722932814\n",
      "64/64 [==============================] - 92s 1s/step - loss: 0.6462 - accuracy: 0.6483 - val_loss: 0.5762 - val_accuracy: 0.7041\n",
      "16/16 [==============================] - 7s 459ms/step\n",
      "64/64 [==============================] - 89s 1s/step - loss: 1.0710 - accuracy: 0.3931 - val_loss: 1.0354 - val_accuracy: 0.4438\n",
      "16/16 [==============================] - 7s 436ms/step\n",
      "juntos: 0.4201165516321892\n",
      "26/26 [==============================] - 37s 1s/step - loss: 1.0904 - accuracy: 0.3867 - val_loss: 1.0689 - val_accuracy: 0.4602\n",
      "8/8 [==============================] - 3s 340ms/step\n",
      "fem: 0.4405844878043779\n",
      "39/39 [==============================] - 62s 2s/step - loss: 1.0941 - accuracy: 0.3810 - val_loss: 1.0576 - val_accuracy: 0.4484\n",
      "9/9 [==============================] - 4s 430ms/step\n",
      "masc: 0.33377279718743136\n",
      "separado: 0.44620366542648476\n",
      "64/64 [==============================] - 107s 2s/step - loss: 0.6465 - accuracy: 0.6463 - val_loss: 0.5741 - val_accuracy: 0.7377\n",
      "16/16 [==============================] - 9s 554ms/step\n",
      "64/64 [==============================] - 106s 2s/step - loss: 1.0737 - accuracy: 0.3966 - val_loss: 1.0371 - val_accuracy: 0.4517\n",
      "16/16 [==============================] - 9s 597ms/step\n",
      "juntos: 0.43549298569509537\n",
      "26/26 [==============================] - 28s 1s/step - loss: 1.0906 - accuracy: 0.3966 - val_loss: 1.0683 - val_accuracy: 0.4328\n",
      "7/7 [==============================] - 2s 317ms/step\n",
      "fem: 0.39277930333032307\n",
      "39/39 [==============================] - 88s 2s/step - loss: 1.0912 - accuracy: 0.3785 - val_loss: 1.0553 - val_accuracy: 0.4542\n",
      "10/10 [==============================] - 6s 619ms/step\n",
      "masc: 0.34111692514321\n",
      "separado: 0.4260679971183136\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RESULTADOS FINAIS\n",
      "flat: 0.4276215272421511\n",
      "local fem: 0.39125214700977823\n",
      "local masc: 0.33294109435338154\n",
      "hierq: 0.4262659975876993\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "VETORES\n",
      "flat: [0.4337421742227465, 0.40730170532075355, 0.42873082520284944, 0.40638576195135245, 0.45169742730209905, 0.43384843369964105, 0.42882528385513563, 0.4300741235396484, 0.4201165516321892, 0.43549298569509537]\n",
      "local fem: [0.3980842911877394, 0.37423946483625664, 0.3412698412698412, 0.35371318822023046, 0.4342227202519761, 0.3950756558331096, 0.39179621484291943, 0.39075630252100835, 0.4405844878043779, 0.39277930333032307]\n",
      "local masc: [0.3063554802685237, 0.34371643394199786, 0.3289549772821148, 0.33571393145861234, 0.3506219692177946, 0.313433538641201, 0.3387790775850477, 0.3369458128078818, 0.33377279718743136, 0.34111692514321]\n",
      "hierq: [0.40223775987569876, 0.4257702079938321, 0.41055782445295214, 0.4143108220682059, 0.45028180354267316, 0.42923219607127655, 0.4292905270342742, 0.4287071722932814, 0.44620366542648476, 0.4260679971183136]\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(r\"C:\\Users\\alici\\Documents\\tcc\\github2\\tcc-v2\\blogset-br\\particoes\\houdout\\train.csv\")\n",
    "df_test = pd.read_csv(r\"C:\\Users\\alici\\Documents\\tcc\\github2\\tcc-v2\\blogset-br\\particoes\\houdout\\test.csv\")\n",
    "\n",
    "f = []\n",
    "l_fem = []\n",
    "l_masc = []\n",
    "h_total = []\n",
    "for _ in range(10):\n",
    "    X_train = df_train[\"Texts\"].apply(clean_text).to_numpy()\n",
    "    X_test = df_test[\"Texts\"].apply(clean_text).to_numpy()\n",
    "    y_train_gender = df_train[\"GenderClass\"].to_numpy()\n",
    "    y_test_gender = df_test[\"GenderClass\"].to_numpy()\n",
    "\n",
    "    num_words = []\n",
    "    for text in (X_train.tolist()+X_test.tolist()):\n",
    "        num_words.append(len(text.split()))\n",
    "\n",
    "    mean = sum(num_words)//len(num_words)\n",
    "\n",
    "    train_texts = X_train.tolist()\n",
    "    test_texts = X_test.tolist()\n",
    "\n",
    "    tfidfvec = TfidfVectorizer(max_features = mean, max_df=0.9)\n",
    "    tfidfvec.fit(train_texts)\n",
    "    tfidf_train = tfidfvec.transform(train_texts).toarray()\n",
    "    tfidf_test = tfidfvec.transform(test_texts).toarray()\n",
    "\n",
    "    X_train = tfidf_train.reshape(tfidf_train.shape[0],tfidf_train.shape[1],1)\n",
    "    X_test = tfidf_test.reshape(tfidf_test.shape[0],tfidf_test.shape[1],1)\n",
    "\n",
    "    y_train_gander_cat = keras.utils.to_categorical(y_train_gender,num_classes=2)\n",
    "    y_test_gender_cat = keras.utils.to_categorical(y_test_gender,num_classes=2)\n",
    "\n",
    "    size = X_test.shape[1]\n",
    "\n",
    "    model_gender = Sequential()\n",
    "    model_gender.add(Conv1D(filters = 100, \n",
    "                        kernel_size = 3,\n",
    "                        strides = 1, \n",
    "                        activation = 'relu', \n",
    "                        input_shape = (size, 1) ))\n",
    "    model_gender.add(MaxPooling1D(pool_size = 4, strides = 1))\n",
    "    model_gender.add(Activation('relu')) # add layer\n",
    "    model_gender.add(Flatten())\n",
    "    model_gender.add(Dropout(0.4))\n",
    "    model_gender.add(Dense(units = 512, activation = 'relu')) #add relu\n",
    "    model_gender.add(Dense(units = 2, activation = 'softmax'))\n",
    "    model_gender.compile(loss='categorical_crossentropy', optimizer = Adadelta(\n",
    "        learning_rate=1, name=\"Adadelta\"\n",
    "    ), metrics = ['accuracy'])\n",
    "\n",
    "    model_gender.fit(X_train,y_train_gander_cat,validation_data=(X_test,y_test_gender_cat), batch_size=32)\n",
    "\n",
    "    y_pred_gender = model_gender.predict(\n",
    "        X_test\n",
    "    )\n",
    "\n",
    "    y_pred_list_gender = [np.argmax(x, axis=-1) for x in y_pred_gender]\n",
    "\n",
    "    df_test[\"PredictGender\"] = y_pred_list_gender\n",
    "\n",
    "    y_train_age = df_train[\"AgeClass\"].to_numpy()\n",
    "    y_test_age = df_test[\"AgeClass\"].to_numpy()\n",
    "\n",
    "    y_train_age = keras.utils.to_categorical(y_train_age,num_classes=3)\n",
    "    y_test_age_cat = keras.utils.to_categorical(y_test_age,num_classes=3)\n",
    "\n",
    "    model_age = Sequential()\n",
    "    model_age.add(Conv1D(filters = 100, \n",
    "                        kernel_size = 3,\n",
    "                        strides = 1, \n",
    "                        activation = 'relu', \n",
    "                        input_shape = (size, 1) ))\n",
    "    model_age.add(MaxPooling1D(pool_size = 4, strides = 1))\n",
    "    model_age.add(Activation('relu')) # add layer\n",
    "    model_age.add(Flatten())\n",
    "    model_age.add(Dropout(0.4))\n",
    "    model_age.add(Dense(units = 512, activation = 'relu')) #add relu\n",
    "    model_age.add(Dense(units = 3, activation = 'softmax'))\n",
    "    model_age.compile(loss='categorical_crossentropy', optimizer = Adadelta(\n",
    "        learning_rate=1, name=\"Adadelta\"\n",
    "    ), metrics = ['accuracy'])\n",
    "\n",
    "    model_age.fit(X_train,y_train_age,validation_data=(X_test,y_test_age_cat), batch_size=32)\n",
    "\n",
    "    y_pred_age = model_age.predict(\n",
    "        X_test\n",
    "    )\n",
    "\n",
    "    y_pred_list_age = [np.argmax(x, axis=-1) for x in y_pred_age]\n",
    "\n",
    "    print(\"juntos: \", end=\"\")\n",
    "    print(metrics.f1_score(y_test_age, y_pred_list_age, average='macro'))\n",
    "    f.append(metrics.f1_score(y_test_age, y_pred_list_age, average='macro'))\n",
    "\n",
    "    df_train_fem = df_train[df_train[\"GenderClass\"]==1]\n",
    "    df_test_fem = df_test[df_test[\"PredictGender\"]==1]\n",
    "\n",
    "    X_train_fem = df_train_fem[\"Texts\"].apply(clean_text).to_numpy()\n",
    "    X_test_fem = df_test_fem[\"Texts\"].apply(clean_text).to_numpy()\n",
    "    y_train_fem = df_train_fem[\"AgeClass\"].to_numpy()\n",
    "    y_test_fem = df_test_fem[\"AgeClass\"].to_numpy()\n",
    "\n",
    "    num_words_fem = []\n",
    "    for text in (X_train_fem.tolist()+X_test_fem.tolist()):\n",
    "        num_words_fem.append(len(text.split()))\n",
    "\n",
    "    mean_fem = sum(num_words_fem)//len(num_words_fem)\n",
    "\n",
    "    train_texts_fem = X_train_fem.tolist()\n",
    "    test_texts_fem = X_test_fem.tolist()\n",
    "\n",
    "    tfidfvec_fem = TfidfVectorizer(max_features = mean_fem, max_df=0.9)\n",
    "    tfidfvec_fem.fit(train_texts_fem)\n",
    "    tfidf_train_fem = tfidfvec_fem.transform(train_texts_fem).toarray()\n",
    "    tfidf_test_fem = tfidfvec_fem.transform(test_texts_fem).toarray()\n",
    "\n",
    "    X_train_fem = tfidf_train_fem.reshape(tfidf_train_fem.shape[0],tfidf_train_fem.shape[1],1)\n",
    "    X_test_fem = tfidf_test_fem.reshape(tfidf_test_fem.shape[0],tfidf_test_fem.shape[1],1)\n",
    "\n",
    "    y_train_fem = keras.utils.to_categorical(y_train_fem,num_classes=3)\n",
    "    y_test_fem_cat = keras.utils.to_categorical(y_test_fem,num_classes=3)\n",
    "\n",
    "    size_fem = X_test_fem.shape[1]\n",
    "\n",
    "    model_fem = Sequential()\n",
    "    model_fem.add(Conv1D(filters = 100, \n",
    "                        kernel_size = 3,\n",
    "                        strides = 1, \n",
    "                        activation = 'relu', \n",
    "                        input_shape = (size_fem, 1) ))\n",
    "    model_fem.add(MaxPooling1D(pool_size = 4, strides = 1))\n",
    "    model_fem.add(Activation('relu')) # add layer\n",
    "    model_fem.add(Flatten())\n",
    "    model_fem.add(Dropout(0.4))\n",
    "    model_fem.add(Dense(units = 512, activation = 'relu')) #add relu\n",
    "    model_fem.add(Dense(units = 3, activation = 'softmax'))\n",
    "\n",
    "    model_fem.compile(loss='categorical_crossentropy', optimizer = Adadelta(\n",
    "        learning_rate=1, name=\"Adadelta\"\n",
    "    ), metrics = ['accuracy'])\n",
    "\n",
    "    model_fem.fit(X_train_fem,y_train_fem,validation_data=(X_test_fem, y_test_fem_cat), batch_size=32)\n",
    "\n",
    "    y_pred_fem = model_fem.predict(\n",
    "        X_test_fem\n",
    "    )\n",
    "\n",
    "    y_pred_list_fem = [np.argmax(x, axis=-1) for x in y_pred_fem]\n",
    "    print(\"fem: \", end=\"\")\n",
    "    print(metrics.f1_score(y_test_fem, y_pred_list_fem, average='macro'))\n",
    "    l_fem.append(metrics.f1_score(y_test_fem, y_pred_list_fem, average='macro'))\n",
    "\n",
    "\n",
    "    df_train_masc = df_train[df_train[\"GenderClass\"]==0]\n",
    "    df_test_masc = df_test[df_test[\"PredictGender\"]==0]\n",
    "\n",
    "    X_train_masc = df_train_masc[\"Texts\"].apply(clean_text).to_numpy()\n",
    "    X_test_masc = df_test_masc[\"Texts\"].apply(clean_text).to_numpy()\n",
    "    y_train_masc = df_train_masc[\"AgeClass\"].to_numpy()\n",
    "    y_test_masc = df_test_masc[\"AgeClass\"].to_numpy()\n",
    "\n",
    "    num_words_masc = []\n",
    "    for text in (X_train_masc.tolist()+X_test_masc.tolist()):\n",
    "        num_words_masc.append(len(text.split()))\n",
    "\n",
    "    mean_masc = sum(num_words_masc)//len(num_words_masc)\n",
    "\n",
    "    train_texts_masc = X_train_masc.tolist()\n",
    "    test_texts_masc = X_test_masc.tolist()\n",
    "\n",
    "    tfidfvec_masc = TfidfVectorizer(max_features = mean_masc, max_df=0.9)\n",
    "    tfidfvec_masc.fit(train_texts_masc)\n",
    "    tfidf_train_masc = tfidfvec_masc.transform(train_texts_masc).toarray()\n",
    "    tfidf_test_masc = tfidfvec_masc.transform(test_texts_masc).toarray()\n",
    "\n",
    "    X_train_masc = tfidf_train_masc.reshape(tfidf_train_masc.shape[0],tfidf_train_masc.shape[1],1)\n",
    "    X_test_masc = tfidf_test_masc.reshape(tfidf_test_masc.shape[0],tfidf_test_masc.shape[1],1)\n",
    "\n",
    "    y_train_masc = keras.utils.to_categorical(y_train_masc,num_classes=3)\n",
    "    y_test_masc_cat = keras.utils.to_categorical(y_test_masc,num_classes=3)\n",
    "\n",
    "    size_masc = X_test_masc.shape[1]\n",
    "\n",
    "    model_masc = Sequential()\n",
    "    model_masc.add(Conv1D(filters = 100, \n",
    "                        kernel_size = 3,\n",
    "                        strides = 1, \n",
    "                        activation = 'relu', \n",
    "                        input_shape = (size_masc, 1) ))\n",
    "    model_masc.add(MaxPooling1D(pool_size = 4, strides = 1))\n",
    "    model_masc.add(Activation('relu')) # add layer\n",
    "    model_masc.add(Flatten())\n",
    "    model_masc.add(Dropout(0.4))\n",
    "    model_masc.add(Dense(units = 512, activation = 'relu')) #add relu\n",
    "    model_masc.add(Dense(units = 3, activation = 'softmax'))\n",
    "\n",
    "    model_masc.compile(loss='categorical_crossentropy', optimizer = Adadelta(\n",
    "        learning_rate=1, name=\"Adadelta\"\n",
    "    ), metrics = ['accuracy'])\n",
    "\n",
    "    model_masc.fit(X_train_masc,y_train_masc,validation_data=(X_test_masc,y_test_masc_cat), batch_size=32)\n",
    "\n",
    "    y_pred_masc = model_masc.predict(\n",
    "        X_test_masc\n",
    "    )\n",
    "\n",
    "    y_pred_list_masc = [np.argmax(x, axis=-1) for x in y_pred_masc]\n",
    "\n",
    "    print(\"masc: \", end=\"\")\n",
    "    print(metrics.f1_score(y_test_masc, y_pred_list_masc, average='macro'))\n",
    "    l_masc.append(metrics.f1_score(y_test_masc, y_pred_list_masc, average='macro'))\n",
    "\n",
    "    y_test_sep = y_test_fem.tolist() + y_test_masc.tolist()\n",
    "    y_pred_list_sep = y_pred_list_fem + y_pred_list_masc\n",
    "    print(\"separado: \", end=\"\")\n",
    "    print(metrics.f1_score(y_test_sep, y_pred_list_sep, average='macro'))\n",
    "    h_total.append(metrics.f1_score(y_test_sep, y_pred_list_sep, average='macro'))\n",
    "\n",
    "print(\"\\n\\n\\n\\n\\n\\nRESULTADOS FINAIS\")\n",
    "print(\"flat: \", end=\"\")\n",
    "print(sum(f)/len(f))\n",
    "print(\"local fem: \", end=\"\")\n",
    "print(sum(l_fem)/len(l_fem))\n",
    "print(\"local masc: \", end=\"\")\n",
    "print(sum(l_masc)/len(l_masc))\n",
    "print(\"hierq: \", end=\"\")\n",
    "print(sum(h_total)/len(h_total))\n",
    "\n",
    "print(\"\\n\\n\\n\\n\\n\\nVETORES\")\n",
    "print(\"flat: \", end=\"\")\n",
    "print(f)\n",
    "print(\"local fem: \", end=\"\")\n",
    "print(l_fem)\n",
    "print(\"local masc: \", end=\"\")\n",
    "print(l_masc)\n",
    "print(\"hierq: \", end=\"\")\n",
    "print(h_total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac26e9ee9434047e2b6179ca7c094dd6d7a5c4307efa62cbdc343ee78cec5e23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
